---
title: "Rejection Sampling"
author: "Michaela Lukacova (dns525)"
institute: "University of Copenhagen"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    css: themer-new.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      ratio: 16:9
      countIncrementalSlides: true
      navigation:
        scroll: false
---
<style type="text/css">
.remark-slide-content {
    font-size: 18px;
        padding: 1em 4em 1em 4em;
    }
.remark-slide-content > h1 {
  font-size: 40px;
}
.remark-slide-scaler {
    overflow-y: auto;
    overflow-x: auto;
}
</style>

```{r, include=FALSE, eval = FALSE}
rmarkdown::render('presentation.rmd')
```

```{r xaringan-themer, include = FALSE, warning = FALSE}
library(xaringanthemer)
library(CSwR)
style_mono_accent(
 base_color = "#4f7942")
```

```{r packages, echo=FALSE, warning=FALSE, message=FALSE}
library(microbenchmark)
library(bench)
library(tidyverse)
library(profvis)
library(bench)
library(Rcpp)
library(knitr)
library(testthat)
knitr::opts_chunk$set(fig.retina = 2)
theme_set(
  theme_bw(base_size = 18) +  # Set base font size and family
    theme(
      text = element_text(size = 15),           # Adjust text size
    )
)
```

```{r source, echo = FALSE, warning=FALSE, message=FALSE}
source("~/Desktop/Uni/5aar/CompStat/comp_stat/Michaela/Univariate_Simulation_ML/f_star.R")
source("~/Desktop/Uni/5aar/CompStat/comp_stat/Michaela/Univariate_Simulation_ML/rejec_sampler.R")
source("~/Desktop/Uni/5aar/CompStat/comp_stat/Michaela/Smoothing_ML/my_sample.R")
source("~/Desktop/Uni/5aar/CompStat/comp_stat/Michaela/Univariate_Simulation_ML/rejec_samp_vec.R")
Rcpp::sourceCpp("~/Desktop/Uni/5aar/CompStat/comp_stat/Michaela/Univariate_Simulation_ML/gauss_rejec_cpp.cpp")
source("~/Desktop/Uni/5aar/CompStat/comp_stat/Michaela/Univariate_Simulation_ML/piecewise_linear.R")
```


### Introduction and outline

- We are given a Poisson data set with 100 rows and $2$ variables $z \in \{0,1,...,5\}$ and $x \in \mathbb{R}_+$

- We wish to sample from the distribution on $[0, \infty)$ with density function 
$$f(y) \propto \prod_{i=1}^{100} \exp \left( yx_i z_i - \exp(yx_i) \right) =  \exp \left( y\left(\sum_{i=1}^{100}x_i z_i\right) - \sum_{i=1}^{100}\exp(yx_i) \right) = f^*(y)$$
- We wish to do this by
  + Implementing rejection sampling from the distribution with density $f$
  + Using a Gaussian envelope
  + Using a piecewise log-affine envelope

- Comparison of the two methods

---
### Rejection sampling

The procedure:

- $f$ is the density of the distribution we want to draw samples from. $g$ is our envelope.  

- Find $\alpha \in (0,1]$ such that $\alpha f(y) \leq g(y)$

- Sample proposals $X_1$, $X_2$, ... with density $g$ 

- Sample $U_1$, $U_2$, ... from a uniform distribution on $[0,1]$

- Rejection sampling accepts the proposal $X_n$ for which it holds $U_n \leq \alpha \frac{f(X_n)}{g(X_n)}$

- Thm. 6.1 in CSWR states that the accepted samples are distributed according to $f$.

- The procedure works even if we only know the densities up to a constant of proportionality.

---
### The Gaussian Envelope

The Gaussian envelop is of the form

$$g(y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( - \frac{(y- \mu)^2}{2\sigma^2}\right)$$

Plot of $f^*$ 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
ggplot() +
  geom_function(fun = f_star_vec) +  
  labs(x = expression(y),
       y = expression({f^{"*"}}(y)))
```

We can determine the proportionality constant $f^*(y) = c f(y)$ by integrating the function $f^*$. 

```{r, echo = FALSE}
c_true <- 1 / integrate(f_star_vec, lower = 0, upper = Inf, abs.tol = 10^(-60))$value
c_true %>% kable(col.names = "c") %>% kableExtra::kable_styling(full_width = FALSE, position = "center")
```


---
### Optimal mean parameter
- The Gaussian density has two parameters, the mean $\mu$ and the variance $\sigma^2$ 

- The envelope should be as tight as possible

  + Due to symmetry we will pick the max of the $f^*$ function as the mean parameter

```{r, echo = FALSE}
mu_opt <- optimize(function(y) -f_star(y), interval = c(0.2, 0.3))$minimum
mu_opt %>% kable(col.names = c("\u03bc")) %>% kableExtra::kable_styling(full_width = FALSE, position = "center")
```

- Still another parameter to determine: $\sigma$

  + Can be determined by considering the acceptance rates associated to the different variance parameters
  
  + And picking the variance that maximizes the acceptance rate. 
  
---
### Optimal variance parameter

For $\alpha' = c \alpha$ the envelope should fulfill

$$f^*(y) \alpha' \leq g(y)$$

Rearranging the above equation 

$$ \alpha' \leq \frac{g(y)}{f^*(y)}$$

Thus we for a specific $g$ find $\alpha'$ by

$$\alpha' = \min_{y \in \mathbb{R}_+} \left\{ \frac{g(y)}{f^*(y)} \right\}$$

Finding the largest $\alpha$ corresponds to finding the largest $\alpha'$, which makes the following a sensible choice of variance parameter

$$\sigma_{opt} = \arg \max_{\sigma} \min_{y \in \mathbb{R}_+} \left\{ \frac{g(y)}{f^*(y)} \right\}$$

---
### Optimal variance parameter

By deriving the second derivative of the ratio $\frac{g(y)}{f^*(y)}$ we see that the function is not convex. Below we plot the ratio for $\sigma = 0.05$. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
ggplot() +
  geom_function(fun = plot_ratio) +
  xlim(0.01,0.6)+  
  labs(x = expression(y),
       y = "ratio",
       title =  expression("Ratio for " * sigma * " = 0.05"))
```

So when we look for the minimum of the ratio, we might end up in a local minimum. We will, since this is a relatively small problem, resort to a simple way of finding the $\sigma_{opt}$, namely taking the minimum over a grid of points. This minimum will be our $\alpha'$. 

---
### Optimal variance parameter

We for a sequence of $\sigma$ values ranging from $0.01$ to $0.2$ determine the minimum of the ratio $\frac{g(y)}{f^*(y)}$ for a sequence of $y$ values ranging from $0.01$ to $0.2$.

```{r, echo = FALSE}
sigma_vals <- seq(0.01, 0.2, length.out = 10^3)
y_vals <- seq(0.01, 0.5, length.out = 10^3)
alpha_prime <- numeric(10^4)

for(i in seq_along(sigma_vals)){
  ratio_vals <- ratio_vec(y_vals, mu = mu_opt, sigma = sigma_vals[i])
  alpha_prime[i] <- min(ratio_vals)
}
```

We find the largest $\alpha'$

```{r, echo = FALSE}
max_i <- which(alpha_prime == max(alpha_prime))
alpha_p <- alpha_prime[max_i]
alpha_p %>% kable(col.names = paste(c("\u03b1"),"'")) %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center")
```

And the corresponding $\sigma$ value.
```{r, echo = FALSE}
sigma_opt <- sigma_vals[max_i]
sigma_opt %>% kable(col.names = c("\u03c3")) %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center")

# Envelope
g <- function(y) dnorm(y, mean = mu_opt, sd = sigma_opt)
```

Now we have our Gaussian envelope!

---
### The envelope plotted with the target distribution

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
f_star_alpha <- function(y) f_star_vec(y) * alpha_p

ggplot() +
  geom_function(fun = f_star_alpha, aes(color = "Prop. density")) + 
  geom_function(fun = g, aes(color = "Envelope"), linetype = "dashed")+
  labs(x = expression(y),
       y = expression(density))+
  scale_color_manual(values = c("Prop. density" = "purple3", "Envelope" = "hotpink"))
```

---
### Testing

We test that the envelope indeed covers $f^*$ for a grid of $y$ values between $0$ and $1$. By plotting the differences

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
ys <- seq(0.01, 0.7, by = 0.001)
diffs <- g(ys) -  f_star_alpha(ys)

ggplot(tibble(x = ys, y = diffs), aes(x = x, y = y)) +
  geom_line(color = "purple3") +
  labs(x = "y", y = "Difference")
```

And testing that the differences are non-negative using `test_that`

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
test_that("The envelope covers the proportional target density", {
  expect_true(all(f_star_alpha(ys) <= g(ys)))
})
```
---
### Rejection sampling using Gaussian envelope

We implement a naive rejection sampler `rs_gauss`, by specifying the parameters of the Gaussian envelope and the target function.

```{r}
rs_gauss <- gauss_rej(mu_opt, sigma_opt, alpha_p, f_star)
```

`rs_gauss` is a function

- That takes as input a sample size $n$.

- Returns a sample drawn from the given distribution together with an estimated acceptance rate. 

- The implementation performs the rejection sampling procedure in a naive way.

  + Draws a uniform variable $U$ and a variable from the envelope distribution $Y$
  + Rejects if $U >  \alpha' \frac{f^*(Y) }{g(Y)}$
  + Continues until we have $n$ accepted samples

We create an S3 class `sampling_object`. With a print method

```{r, echo=TRUE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
samp0 <- my_sample(n = 10^5, sampler = rs_gauss)
samp0
```

---
### Rejection sampling using Gaussian envelope

The target distribution can be estimated by

$$f(y) = cf^*(y)  = \frac{\alpha'}{\hat{\alpha}} f^*(y)$$

Using the estimated acceptance rate $\hat{\alpha}$

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
c <- alpha_p /samp0$Accept
f_est <- function(y) f_star_vec(y) * c
f_true <- function(y) f_star_vec(y) * c_true
```

A historgram of the sample distribution is plotted together with the estimated density and the true density of the target distribution by the `plot` method

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
plot(samp0)+
  geom_function(fun = f_est, aes(color = "Estimated f"))+
  geom_function(fun = f_true, aes(color = "True f"))+
  scale_color_manual(values = c("Estimated f" = "purple3", "True f" = "steelblue"))
```

---
### Optimizing

```{r, echo = FALSE}
profvis::profvis({
  
  gauss_rej <- function(mu, sigma, alpha, f) {
  sampler <-function(n){
      y <- numeric(n)
      counter <- 0
      for (i in 1:n) {
        reject <- TRUE
        while (reject) {
          y0 <- rnorm(1, mu, sigma)
          u <- runif(1)
          reject <- u > f(y0) / dnorm(y0, mu, sigma) * alpha
          counter <- counter + 1
        }
        y[i] <- y0
      }
      return(list("sample" = y, "accept" = n / counter))
    }
    return(sampler)
  }

  rs_gauss <- gauss_rej(mu_opt, sigma_opt, alpha_p, f_star)
  
  rs_gauss(10^5)
})
```

---
### Optimizing: Vectorizing

- Sampling $m$ pairs of variables at a time, until we reach the desired random sample size. 

- $m$ is adapted for each iteration.

This is done by implementing the two functions `vec_f_random` and `rng_wrapper`.

- `vec_f_random` samples $m$ pairs of variables, and returns the random number of accepted samples following our desired distribution. 

- `rng_wrapper` is a wrapper function that returns a random sampler that samples exactly $n$ pairs of variables, using an input function `rng`. The function returned by `rng_wrapper` calls `rng(M)` until we have $n$ accepted samples. Where $M$ is adapted to the estimated acceptance rate. 

```{r}
vec_f_random <- function(m, mu, sigma, f, alpha_p) {
  y <- rnorm(m, mu, sigma)
  u <- runif(m)
  accept <- u <= f(y) / dnorm(y, mean = mu, sd = sigma) * alpha_p
  
  return("Sample" = y[accept])
}

rng_wrapper <- function(rng, fact = 1.05, M_min = 100) {
  function(N, ...) {
    j <- 0     # The number of iterations
    l <- 0     # The number of accepted samples
    counter <- 0 # The number of proposals
    
    x <- list()
    
    while (l < N) {
      j <- j + 1 
      M <- floor(max(fact * (N - l), M_min))
      x[[j]] <- rng(M, ...)
      counter <- counter + M
      l <- l + length(x[[j]])
      # Update 'fact' by estimated acceptance probability l / n
      if (j == 1) fact <- fact * N / l
    }
    return(list("sample" = unlist(x)[1:N], "accept" = length(unlist(x)) / counter))
  }
}
```

---
### Check of the vectorized version

```{r, echo = FALSE}
inside_func <- function(n) vec_f_random(n, mu_opt, sigma_opt, f_star_vec, alpha_p)
rs_gauss_vec <- rng_wrapper(inside_func)
```

A new `sampling_object`. 

```{r, echo = TRUE}
samp1 <- my_sample(n = 10^5, sampler = rs_gauss_vec)
samp1
```

To check whether the drawn samples result in the desired density we plot the histogram of the sample together with the estimated density and the true density. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
c <- alpha_p /samp1$Accept
f_est <- function(y) f_star_vec(y) * c
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
plot(samp1)+
  geom_function(fun = f_est, aes(color = "Estimated f"))+
  geom_function(fun = f_true, aes(color = "True f"))+
  scale_color_manual(values = c("Estimated f" = "purple3", "True f" = "steelblue"))
```

---
### Profiling

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
profvis::profvis({
  vec_f_random <- function(m, mu, sigma, f, alpha_p) {
    y <- rnorm(m, mu, sigma)
    u <- runif(m)
    accept <- u <= f(y) / dnorm(y, mean = mu, sd = sigma) * alpha_p
    
    return("Sample" = y[accept])
  }
  
  rng_wrapper <- function(rng, fact = 1.05, M_min = 100) {
    function(N, ...) {
      j <- 0     # The number of iterations
      l <- 0     # The number of accepted samples
      counter <- 0 # The number of proposals
      
      x <- list()
      
      while (l < N) {
        j <- j + 1 
        M <- floor(max(fact * (N - l), M_min))
        x[[j]] <- rng(M, ...)
        counter <- counter + M
        l <- l + length(x[[j]])
        # Update 'fact' by estimated acceptance probability l / n
        if (j == 1) fact <- fact * N / l
      }
      return(list("sample" = unlist(x)[1:N], "accept" = length(unlist(x)) / counter))
    }
  }

  rs_gauss_vec(10^5)

})
```

---
### Rcpp

As a last attempt at optimizing we implement the rejection sampling procedure with the Gaussian envelope in Rcpp. 

We again check that the random sampler produces reasonable outputs. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
samp_rcpp <- gauss_rej_cpp(10^5, mu_opt, sigma_opt, alpha_p, x, sum1)

ggplot(data = tibble(y = samp_rcpp$sample)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = y, y = ..density..)) +
  geom_function(fun = f_true, aes(color = "True f"))+
  scale_color_manual(values = c("True f" = "purple3"))+
  labs(title = "Histogram of sample", x = "y", y = "Density")
```

---
### Benchmarking

Then we benchmark the three implementations

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
rng_bench <- bench::press(
  k = 10^(2:4),
  {
    bench::mark(
      "Naive" =  rs_gauss(k),
      "Vectorized" = rs_gauss_vec(k),
      "Rcpp" = gauss_rej_cpp(k, mu_opt, sigma_opt, alpha_p, x, sum1),
      check = FALSE
    )
  }
)

rng_bench %>% 
  mutate(expr = as.character(expression), median = as.numeric(median)) %>% 
  ggplot(aes(k, median, color = expr)) + geom_point() + scale_y_log10() +
  geom_line() + labs(y = "time (ms)")
```

---
### Piecewise log-affine envelope

Since

$$\frac{d^2}{dy^2} \log f^*(y) = \frac{d^2}{dy^2} \left( y\left(\sum_{i=1}^{100}x_i z_i\right) - \sum_{i=1}^{100}\exp(yx_i) \right) = - \sum_{i=1}^{100}x_i^2 \exp(yx_i) < 0$$

Our target density is proportional to a log concave function. We can thus construct a piecewise log-affine envelope as described in 6.2 of CSWR. 

The function `piece_lin_rejec_samp` performs rejection sampling using a piecewise log affine envelope in this way. 

- Takes as input a sequence of $y$-values and a number $N$ of draws to make
- The algorithm computes an envelope of the form

$$g(y) = \frac{1}{d} \exp \left\{ V(x) \right\} = \frac{1}{d} \exp \left\{ \sum_{i=1}^m (a_i y + b_i) 1_{I_i}(y) \right\}$$
- Performs rejection sampling using this envelope
- Returns a random number of accepted proposals

---
### Piecewise log-affine envelope

For a sequence of equidistant $y$ values of length $10$ ranging from $0.05$ to $0.45$ we construct a rejection sampler.

```{r, echo = FALSE}
ys <- seq(0.05,0.45, length.out = 10)
pa_sample <- rng_wrapper(piece_lin_rejec_samp)
pa_sample2 <- function(n) pa_sample(n, ys)
```

We again create a `sampling_object`. This time using the piecewise log-affine rejection sampler. 

```{r}
samp2 <- my_sample(n = 10^5, sampler = pa_sample2)
samp2
```

```{r, echo = FALSE}
as <- sapply(ys, a_i, simplify = TRUE)
bs <- mapply(FUN = b_i, ys, as)
n <- length(bs)
zs <- c(-Inf, mapply(FUN = z_i, as[1:(n-1)], as[2:n], bs[1:(n-1)], bs[2:n]), Inf)

pl_env <- function(y){
  index <- which(y >= zs[1:(length(zs)-1)] & y < zs[2:length(zs)])  
  return(exp(as[index] * y + bs[index]) * c_true)
}

pl_env_vec <- Vectorize(pl_env)
```

We get a higher acceptance rate than before. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
plot(samp2)+
  geom_function(fun = f_true, aes(x = y, color = "True f"), linewidth = 1.2)+
  geom_function(fun = pl_env_vec, aes(color = "Envelope"), linewidth = 1.2)+
  scale_color_manual(values = c("True f" = "purple1", "Envelope" = "green4"))+
  ylim(0, 8)
```

---
### Profiling

```{r, echo = FALSE}
profvis::profvis({
  f_star <- function(y) exp(y * sum1  - sum(exp(y * x)))

  piece_lin_rejec_samp <- function(N, ys) {
  
    # Calculating a's, b's, z's
    as <- sapply(ys, a_i, simplify = TRUE)
    bs <- mapply(FUN = b_i, ys, as)
    n <- length(bs)
    zs <- c(-Inf, mapply(FUN = z_i, as[1:(n-1)], as[2:n], bs[1:(n-1)], bs[2:n]), Inf)
    
    # Bookkeeping
    # I_i integrals
    R <- r_i(as, bs, zs, n)
    
    # Distribution function (ish)
    Q <- c(0, cumsum(R))
    
    # Drawing from piecewise linear density and uniform
    u0 <- Q[n + 1] * runif(N)
    u <- runif(N)
    
    # Determine the interval that each point belongs to
    geq_z <-outer(u0, Q[1:n], FUN = function(y1, y2) y1 > y2)
    leq_z <-outer(u0, Q[2:(n+1)], FUN = function(y1, y2) y1 <= y2)
    I <- geq_z & leq_z
    
    
    x <- numeric(N)
    accept <- logical(N)
    for(i in 1:N){
      # Finding the interval x_i belongs to
      int <- which(I[i,] == 1)
      
      # Taking the inverse cdf
      x[i] <- log((u0[i] - Q[int]) * as[int] * exp(- bs[int]) + exp(as[int] * zs[int])) / as[int]
      
      # Acceptance step
      accept[i] <- u[i] <=  f_star(x[i]) / exp(as[int] * x[i] + bs[int])
    }

    return(x[accept])
  }

  pa_sample2(10^4)

})
```

Time is spent in the acceptance step, computing the $f^*$ function and drawing from the uniform distribution. 

---
### Optimizing: parallelizing

We parallelize using the package `parallel`, and the function `mclapply`. 

```{r, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
pa_sample_par <- rng_wrapper(piece_lin_rejec_samp_par)
pa_sample_par2 <- function(n) pa_sample(n, ys)


bench_piece1 <- bench::press(
  k = c(100, 500, 1000, 5000, 10^4, 5*10^4, 10^5),
  {
    bench::mark(
      "Not parallelized" =  pa_sample2(k),
      "Parallelized" =  pa_sample_par2(k),
      check = FALSE
    )
  }
)

bench_piece1 %>% 
  mutate(expr = as.character(expression), median = as.numeric(median)) %>% 
  ggplot(aes(k, median, color = expr)) + geom_point() + scale_y_log10() +
  geom_line() + labs(y = "time (ms)")
```

---
### Optimizing: The number of breakpoints 

The envelope will get tighter the finer the grid of $y$'s we provide. We test how the number of breakpoints affects the acceptance rate

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
accept <- numeric(length = 28)
for(i in 3:30){
  accept[i - 2] <- pa_sample(10^3, seq(0.05,0.45, length.out = i))$accept
}

ggplot()+
  geom_line(aes(x= seq(3,30), y = accept), color = "hotpink")+
  labs(x = "Number of breakpoints", 
       y = "Acceptance rate", 
       title = "Acceptance rate as function of number of breakpoints")
```

---
### Optimizing: The number of breakpoints 

The envelope will get tighter the finer the grid of $y$'s we provide. We test how the number of breakpoints affects the runtime

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
bench_piece <- bench::press(
  i = 3:30,
  {
    bench::mark(
      "10^3" =  pa_sample(10^3, seq(0.05,0.45, length.out = i)),
      "10^4" =  pa_sample(10^4, seq(0.05,0.45, length.out = i)),
      "100" =  pa_sample(10^3, seq(0.05,0.45, length.out = i)),
      check = FALSE
    )
  }
)

bench_piece %>% 
  mutate(expr = as.character(expression), median = as.numeric(median)) %>% 
  ggplot(aes(i, median, color = expr)) + geom_point() + scale_y_log10() +
  geom_line() + labs(y = "time (ms)")
```

- Tradeoff?

---
### Comparison

We check that the two sampling procedures result in the same distribution

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
plot_list <- list()
samp_sizes <- c(50, 10^2, 10^3)

set.seed(657)
for(i in 1:3){
  samp_rcpp <- gauss_rej_cpp(samp_sizes[i], mu_opt, sigma_opt, alpha_p, x, sum1)
  samp_piec <- pa_sample(samp_sizes[i], ys)
  
  plot_list[[i]] <- ggplot() + 
  geom_histogram(bins = 30, alpha = 0.5, aes(x = samp_rcpp$sample, fill = "Rcpp Gaussian", y = ..density..)) +
  geom_histogram(bins = 30,  alpha = 0.5, aes(x = samp_piec$sample,fill = "Piece log affine", y = ..density..)) +
  labs(title = paste("n = ", samp_sizes[i]), x = "y",
         y = "Density")+
  scale_fill_manual(values = c("Rcpp Gaussian" = "green3", "Piece log affine" = "blue"))
}


plot_list[[4]] <-  ggplot() + 
  geom_histogram(bins = 30, alpha = 0.5, aes(x = samp2$Sample, fill = "Rcpp Gaussian", y = ..density..)) +
  geom_histogram(bins = 30,  alpha = 0.5, aes(x = samp_rcpp$sample,fill = "Piece log affine", y = ..density..)) +
  labs(title = "n = 10^5", x = "y",
         y = "Density")+
  scale_fill_manual(values = c("Rcpp Gaussian" = "green3", "Piece log affine" = "blue"))


gridExtra::grid.arrange(grobs = plot_list, nrow = 2)
```

They both result in the same distributions.

---
### Benchmarking

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
bench_results2 <- bench::mark(
    "Gaussian vectorized" = rs_gauss_vec(10^4),
    "Rcpp Gaussian" = gauss_rej_cpp(10^4, mu_opt, sigma_opt, alpha_p, x, sum1),
    "Piece log affine" = pa_sample(10^4, ys),
    iterations = 50,
    check = F
)
plot(bench_results2) + ggtitle("n = 10^4")
```

The piecewise log affine envelope is slower. 

---
### Conclusion

- We have implemented rejection sampling using a Gaussian envelope and a piecewise log affine envelope.

- By performing visual tests we have tested that the implemented algorithms draw from the correct distribution

- We have optimized the code by vectorizing, implementing in Rcpp, parallelizing and considering how to select the optimal hyperparameters

- We have implemented an S3 object to improve readability.  

- Comparing the algorithms we have discovered that the piecewise log affine envelope rejection sampler is slower.



Sammenlign evt. standard afvigelse eller andre stÃ¸rrelser. 