
title: 'Smoothing: A. Density Estimation'
author: "Michaela Lukacova"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  fig_height: 5
  fig_width: 5
  theme: flatly
  html_document: null


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


*Implement a kernel density estimator using the Epanechnikov kernel, and implement one or more bandwidth selection algorithms using either AMISE plug-in methods or cross-validation methods. Test the implementation and compare the results with the results of using density() in R.*

*It may be a good idea to use real data to investigate how the bandwidth selection works, but for benchmarking and profiling it is best to use simulated data. Think about how to make your implementation as general and generic as possible.*

```{r, include=FALSE, eval = FALSE}
#rmarkdown::render('presentation.rmd')
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(CSwR)
style_mono_accent(
 base_color = "#4f7942")
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(microbenchmark)
library(profvis)
library(knitr)
library(bench)
library(ggplot2)
library(tidyverse)
library(testthat)
library(Rcpp)
library(parallel)
library(gridExtra)

theme_set(theme_bw())
knitr::opts_chunk$set(fig.retina = 2)
theme_set(
  theme_bw(base_size = 18) +  # Set base font size and family
    theme(
      text = element_text(size = 15),           # Adjust text size
    )
)
```

```{r source, include=FALSE}
source("~/R/comp_stat/Smoothing_ML/AMISE_bw.R")
source("~/R/comp_stat/Smoothing_ML/cv_bw_l.R")
source("~/R/comp_stat/Smoothing_ML/cv_bw_l_fast.R")
source("~/R/comp_stat/Smoothing_ML/density_object.R")
source("~/R/comp_stat/Smoothing_ML/kern_bin.R")
source("~/R/comp_stat/Smoothing_ML/kern_dens_bin.R")
source("~/R/comp_stat/Smoothing_ML/naive_kern_dens.R")
source("~/R/comp_stat/Smoothing_ML/mse_dens.R")
Rcpp::sourceCpp("rcpp_cw.cpp")
```

### Kernel Density Estimation

The kernel density estimators approximate an unknown density of data points with the function

$$ \hat{f}(x) = \frac{1}{hN} \sum_{j=1}^N K\left(\frac{x-x_j}{h}\right)$$

For a given kernel $K: \mathbb{R} \rightarrow \mathbb{R}$ and bandwidth parameter $h$.

In our implementations we will use the Epanechnikov kernel. 

$$K(x)=\frac{3}{4}\left(1-x^2\right) 1_{[-1,1]}(x)$$

### Naive density estimator

We implement a naive density estimator called `kern_dens1`. The function takes a vector of data points $x$, a bandwidth parameter $h$, a number of gridpoints $m$ and a boolean `norm` to normalize the density estimate. The function returns a list with the gridpoints $x$ and the density estimate $y$. The `norm`argument is used to normalize the density estimate, so that the gridpoints are equal to R's `density` function for comparison

```{r}
kern_dens1 <- function(x, h, m = 512, norm = TRUE) {
  
  rg <- range(x)
  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)
  y <- numeric(m)
  
  # we normalize now, so that the gridpoints are equal to r's density function
  if(norm){
    h <- sqrt(5) * h
  }
  
  for (i in seq_along(xx)) {
    
    condition <- abs(xx[i] - x) <= h
    y[i] <- sum((1 - (xx[i] - x)^2 / h^2) * condition)
    
  }
  
  y <- 3 * y / (4 * h * length(x))
  list(x = xx, y = y)
  
}
```

Note that we have already optimized the code a bit in this naive implementation by vectorizing and thinking about performing the operations in the smartest order possible. 


### Simulation of data

To test our naive density estimator, we simulate data by drawing 2 times $500$ points from a normal distribution with respectively mean -3 and mean 3, and standard deviation 2. This way we obtain a bimodal distribution. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
# Simulate data
n <- 500
set.seed(123)
x <- c(rnorm(n, mean = -3, sd = 2), rnorm(n, mean = 3, sd = 2))
x_dens <- function(x) 1/2 * dnorm(x, -3, 2) + 1/2 * dnorm(x,3,2)

p <- ggplot(tibble(x = x), aes(x = x)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = x, y = ..density..)) +
  geom_function(fun = x_dens, alpha = 0.5, aes(color = "True Dens"))+
  scale_color_manual(values = c("True Dens" = "blue", 
                                "CV" = "hotpink", 
                                "AMISE" = "green3"))+
  labs(color = "Density types", title = "Simulated data", x = "x", y = "Density")

p
```


### S3 class

To make the implementation as generel and generic as possible, we have implemented an S3 class `density_object` to store data and bandwidth parameters. It is created by calling the `my_density` function on a vector of data points. 

```{r}
test_obj <- my_density(x)
```

The object has a `plot` method which we use to check how the naive kernel density estimator approximates the simulated data. We call the plot function to check whether our kernel density estimator produces a reasonable approximation of the true density. 

```{r, fig.width=10, fig.height=4, fig.align='center'}
plot(test_obj, h = 0.5)
```


### Check of naive density estimator

We compare the results to the results obtained by using R's `density` function. This we can do by setting the `p` argument in the `plot` method to $2$. 

```{r, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
plot(test_obj, h = 0.5, p = 2)
```

They are practically the same!


### Check of naive density estimator

We further test that the estimates are correct by using the `test_dens` method. This method tests that the absolute distance between the R `density` function and our own function is less than $10^{-3}$ for 4 different $h$ values equally distanced in the interval from $0.2$ to $1$. 

```{r}
test_dens(test_obj)
```


### Binned kernel density estimator

After profiling and benchmarking the naive density function, we see that it is quite a lot slower than the `density` function in R. We implement a binned density estimator `kern_dens_bin` to speed up the density estimation. The binned density estimator is an alteration of the previous density estimator. It has the advantage of computational efficiency. The binned density estimator is computed as 

$$
\hat{f}(x) = \frac{1}{hN} \sum_{i=1}^B n_j K\left(\frac{x-c_j}{h}\right)
$$
The function bins the observations into $B$ equal length bins spanning the length of the $x$ observations. The number of observations in each bin is $n_j$. $c_j$ is the center of each bin. The computational efficiency is achieved by, instead of computing $K$ in each data point, we only compute $K$ in each centerpoint, and then multiply by the number of observations in that bin. The concern could be that we lose accuracy, but as we'll see, this is not a problem. 

```{r}
kern_dens_bin <- function(x, h, m = 512, B = 100, norm = TRUE, bin = kern_bin) {
  rg <- range(x)
  delta <- (rg[2] - rg[1]) / (B - 1)
  c <- seq(rg[1] + delta/2, rg[2] - delta/2, length.out = B)
  n <- bin(x, rg[1], rg[2], B)
  
  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)
  y <- numeric(m)
  
  # we normalize now, so that the gridpoints are equal to r's density function
  if(norm){
    h <- sqrt(5) * h
  }
  
  for (i in seq_along(xx)) {
    condition <- abs(xx[i] - c)  <=  h
    y[i] <- sum(n * (1 - (xx[i] - c)^2 / h^2) * condition)
  }
  
  y <- 3 * y / (4 * h)
  list(x = xx, y = y)
}
```


### Check of binned density estimator

Again we test the implementation by comparing the results to the results obtained by using R's density function. 

```{r, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
plot(test_obj, h = 0.5, binned = TRUE, B = 100)
```

The estimates are very close to beeing the same as when using R's density estimator. We plot the differences.

```{r, message=FALSE, warning=FALSE, echo = FALSE, fig.width=10, fig.height=4, fig.align='center'}
test_dens(test_obj, binned = TRUE, level = 1e-2)

plot_diff <- tibble(x = plot_data(test_obj, h = 0.5, binned = TRUE)$x,
                    "Diffs bin" = plot_data(test_obj, h = 0.5, binned = TRUE)$y - 
                      density(test_obj$x, kernel = "epanechnikov", 0.5)$y,
                    "Diffs naive" = plot_data(test_obj, h = 0.5)$y - 
                      density(test_obj$x, kernel = "epanechnikov", 0.5)$y)

ggplot(data = plot_diff, aes(x = x)) + 
  geom_line(aes(y = `Diffs bin`, color = "Binned")) +
  geom_line(aes(y = `Diffs naive`, color = "Naive")) +
  labs(title = "Differences between R's density function and our own", x = "x", y = "Differences") +
  scale_color_manual(values = c("Binned" = "purple", "Naive" = "hotpink"))

```


By profiling the `kern_dens_bin` function we see that the function is quite fast. All the time is spent in the `kern_bin` function, which is a function that computes the number of points in each bin. 

```{r, message=FALSE, warning=FALSE, echo = FALSE}
y <- rnorm(10^8)
profvis::profvis({
  kern_dens_bin(y, 0.5)
})
```


We vectorize the `kern_bin` function to speed up the computation. The function is implemented as 

```{r}
kern_bin_fast <- function(x, l, u, B) {
  delta <- (u - l) / (B - 1)
  is <- floor((x - l) / delta + 0.5) + 1
  w <- tabulate(is)
  w/sum(w)
}
```

And test that the two functions in fact compute the same

```{r}
sum(kern_bin(x, range(x)[1], range(x)[2], 100) != kern_bin_fast(x, range(x)[1], range(x)[2], 100)) %>% kable()
```


```{r, message=FALSE, warning=FALSE, echo = FALSE, fig.width=10, fig.height=4, fig.align='center'}
# Generate random numbers
set.seed(19)
y <- rnorm(2^12)

dens_bench <- bench::press(
  k = 2^(7:12),
  {
    bench::mark(
      "Vectorized binned density" = kern_dens_bin(x = y[1:k], h = 0.2, bin = kern_bin_fast),
      "Binned density" = kern_dens_bin(y[1:k], 0.2),
      "Naive" = kern_dens1(y[1:k], 0.2),
      check = FALSE
    )
  }
)

dens_bench %>% 
  mutate(expr = as.character(expression), median = as.numeric(median)) %>% 
  ggplot(aes(k, median, color = expr)) + geom_point() + 
  scale_y_log10() +
  geom_line() + labs(y = "time (ms)")
```
Large improvements by using the binned density estimator, and a small improvement vectorizing it. Especially for small $k$. This might be due to the function `tabulate`. 


We will explore two different approaches to bandwidth selection.
- AMISE plugin
- Cross-validation

The AMISE plugin method is based on minimizing the asymptotic mean integrated squared error. And can be seen as finding a suitable trade off between the integrated variance of our density estimator and the bias of the density estimator. In order for the method to be valid, we need to assumme $||f''_0||_2^2$ is finite.

The cross validation method does not rely on asymptotic results, but chooses the optimal bandwidth by minimizing a certain cross validation criterion. We will use a log likelihood criterion.

The CV bandwidth based selection is implemented in the function `cv_bw_l`, and the AMISE bandwidth based selection is implemented in the function `AMISE_bw`. We can access these quantities through the density object. 

```{r, echo = FALSE}
test_obj
```


The Epanechnikov kernel is a square-integrable probability density with mean 0. It can be shown that for the Epanechnikov kernel:

$$
\sigma_K^2 = \frac{1}{5} , \quad
||K||_2^2 = \frac{3}{5}
$$
Where 

$$
\sigma_K^2 = \int x^2 K(x) dx , \quad
||K||_2^2 = \int K(x) ^2 dx
$$

The AMISE is defined as

$$
AMISE(h) = \frac{||K||_2^2}{nh} + \frac{h^4 \sigma_{K}^4 ||f_0''||_2^2}{4} 
$$
$||f''_0||_2^2$ is the squared $L_2$-norm of the true unknown density. 

By minimizing $AMISE(h)$ the asymptotically optimal oracle bandwidth is 

$$
h_N = \left(\frac{||K||_2^2 }{||f''_0||_2^2 \sigma_K^4} \right)^{1/5}n^{-1/5}
$$

Inserting the values we have for the Epanechnikov kernel

$$
h_N = \left(\frac{15 }{||f''_0||_2^2 } \right)^{1/5}n^{-1/5}
$$
We have now arrived at a circular problem. In order to select bandwidth we need to know $f$, but to estimate $f$ we need the bandwidth. A solution to this problem is to estimate $h$ according to Silverman’s rule of thumb, obtain a pilot density estimate $\tilde{f}$ and compute the squared $L_2$-norm, use this estimate to find $h_N$, in order to arrive at our final kernel density estimate. Silvermans rule of thumb assumes that the underlying density is Gaussian, and is known to oversmooth, if the distribution is multimodal. 

Silverman’s rule of thumb for the Epanechnikov kernel is (using the gaussianity assumption)

$$
\hat{h}_n = (40\sqrt{\pi})^{1/5} \tilde{\sigma}n^{-1/5}
$$

Where $\tilde{\sigma} = \min\{\hat{\sigma}, \frac{\operatorname{IQR}}{1.34}\}$. $\hat{\sigma}$ is sensitive to outliers, which is why we use the minimum of this and $IQR$. 

For the Epanechnikov kernel ($H$) with bandwidth $h$ we can compute the squared $L_2$-norm as

$$
||\tilde{f}||^2_2 = \frac{1}{n^2 h^6} \sum_{i=1}^N\sum_{j=1}^N\int H''\left(\frac{x-x_i}{h}\right) H''\left(\frac{x-x_j}{h}\right) dx
$$
### Bandwidth selection: AMISE plugin

We have

$$
H''(x) = -\frac{3}{2} 1_{[-1,1]}(x)
$$
Note

$$
\left(\frac{x-x_i}{h}\right) \in [-1,1] \Leftrightarrow x \in [x_i-r,x_i+r]
$$

So
$$
||\tilde{f}||^2_2 = \frac{9}{4n^2 h^6} \sum_{i=1}^N\sum_{j=1}^N \int_{\max\{x_i - h, x_j -h\}}^{\min\{x_i + h, x_j + h\}} 1 dx = \frac{9}{4n^2 h^6} \sum_{i=1}^N\sum_{j=1}^N  \left(\max\{0,2h - |x_i-x_j|\} \right)
$$


An alternative to finding the optimal bandwidth by the AMISE plugin method is to use cross validation to find the optimal bandwidth. We will use a log likelihood based cross validation criterion, namely

$$
\mathcal{l}_{CV}(h) = \sum_{i=1}^N \log(\hat{f}_h^{-i}(x_i)) 
$$
Here $\hat{f}_h^{-i}$ is the kernel density estimate obtained by leaving out the group containing $x_i$ evaluated in $x_i$, that is
$$
\hat{f}_h^{-i}(x_i) = \frac{1}{hN_i} \sum_{j \in I^{-1}} K\left(\frac{x_i -x_j}{h}\right) = \frac{3}{4hN_i} \sum_{j \in I^{-1}} \left( 1-\left(\frac{x_i -x_j}{h}\right)^2\right) 1_{[-h,h]}(x_i - x_j)
$$
By maximizing this quantity, we can obtain a bandwidth estimate. We first implemented a naive method that for a sequence of bandwidths $(0.01,0.02,...,2)$ computes the log likelihood and picks the smallest bandwidth. We use 5 fold cross validation. This method is quite slow since the log likelihood needs to be computed for every data point for every bandwidth. 

If we profile the function we can identify bottlenecks:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
profvis::profvis({
  cv_bw_l(x)
})
```
The time is spent inside the for loop doing the computations og the $\hat{f}_h^{-i}$'s


The method takes a lot of time. The term $(x_i - x_j)^2$ is being computed over and over for each $h$. We optimize the cross validation band width selection such that this term is computed once, and then used for all $h$. We implement this in the function `cv_bw_l_fast`. We furthermore take the inner for loop and implement it in Rcpp. 

```{r}
cv_bw_l_fast <- function(x, 
                         k = 5,
                         h = seq(0.3, 2, by = 0.01), 
                         loop = inner_loop,
                         do_parallel = FALSE) {
  
  # Partition
  n <- length(x)
  groups <- sample(rep_len(seq(1,k), length.out = n), replace = FALSE)
  
  # number of obs in each group
  N <- sapply(seq(1,k), function(x) sum(groups == x), simplify = TRUE)
  
  # bandwidth log likelihoods and kernel density estimates
  bw_l <- numeric(length(h))
  
  if(do_parallel == TRUE) coress <- detectCores() - 1
  else coress <- 1
  
  # term that does not depend on h
  kern_vals <- outer(x, x, function(x1,y1) (x1 - y1)^2)
  
  bw_l_results <- mclapply(seq_along(h), function(j) {
    kern_vals_h <- 1 - kern_vals / h[j]^2
      
    # Calculating CV density estimates
    f_hat_i <- loop(x, h[j], groups, kern_vals_h, N)
      
    # Calculating log likelihood for bandwidth h[j]
    log_likelihood <- sum(log(f_hat_i))
      
    # Return log likelihood for this bandwidth
    return(log_likelihood)
    }, mc.cores = coress)
    
  bw_l <- unlist(bw_l_results)
  
  # Returning the bandwidth that has the largest likelihood 
  return(h[which.max(bw_l)])
}
```

We test that the rcpp implementations correspond to the R implementation:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
test_that("Rcpp implementation corresponds to R implementation", {
  expect_equal(
    inner_loop_rcpp(x, h, groups, kern_vals_h, N),
    inner_loop(x, h, groups, kern_vals_h, N),
    tolerance = 10^(-13))})
```

As a last attempt at optimizing, we parallelize the folds using the package `parallel`.


To evaluate our optimization we benchmark the naive method, the optimized method and the optimized method with Rcpp, and the optimized method with Rcpp and parallization. 

```{r, message=FALSE, warning=FALSE, echo = FALSE, fig.width=10, fig.height=4, fig.align='center'}
# Generate random numbers
set.seed(19)
y <- rnorm(2^9)

kern_bench <- bench::press(
  k = 2^(7:10),
  {
    bench::mark(
      "Naive" = cv_bw_l(x = y[1:k]),
      "Optimized" = cv_bw_l_fast(x = y[1:k]),
      "Rcpp" = cv_bw_l_fast(x = y[1:k], loop = inner_loop_rcpp),
      "Rcpp and parallel" = cv_bw_l_fast(x = y[1:k], loop = inner_loop_rcpp, do_parallel = TRUE),
      check = FALSE,
      memory = FALSE
    )
  }
)

kern_bench %>% 
  mutate(expr = as.character(expression), median = as.numeric(median)) %>% 
  ggplot(aes(k, median, color = expr)) + geom_point() + 
  scale_y_log10() +
  geom_line() + labs(y = "time (ms)")
```
It is a bit surprising that the Rcpp implementation is not faster than the R version. This must be due to the vectorization of the procedures in the R for loop, the code is already quite efficient. The parallelization really does do a big difference for the computation time. The optimized version is also not that much quicker which is also a bit surprising. This might be due to the fact that we compute a large matrix, and need to access elements many times throughout the procedure. 

The cross validation procedure is random and depends upon how data is split. Below we run the cross validation procedure 30 times to get an idea of the distribution of the estimates. We try both $k = 5$ and $k= 10$, to see whether one of the two is more stable:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'} 
zz <- x[1:500]
est5 <- numeric(30)
est10 <- numeric(30)

for(i in 1:30){
  est5[i] <- cv_bw_l_fast(x = zz, loop = inner_loop_rcpp, do_parallel = TRUE, k = 5)
  est10[i] <- cv_bw_l_fast(x = zz, loop = inner_loop_rcpp, do_parallel = TRUE, k = 10)
}

grid.arrange(
  ggplot(tibble(x = est5), aes(x = x)) + 
    geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = x, y = ..density..)) +
    labs(title = "k = 5", x = "x", y = "Density"),
  ggplot(tibble(x = est10), aes(x = x)) + 
    geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = x, y = ..density..)) +
    labs(title = "k = 10", x = "x", y = "Density"),
  nrow = 1)
```
A larger $k$ seems to stabilize a bit more. 

Our crossvalidation optimal bandwidth:

```{r, message=FALSE, warning=FALSE, echo = FALSE, fig.width=10, fig.height=4, fig.align='center'}
test_obj$cv_bw %>% kable()
test_obj$amise_bw %>% kable()
```

Plotting the two

```{r, message=FALSE, warning=FALSE, echo = FALSE, fig.width=10, fig.height=4, fig.align='center'}
p +
  geom_line(data = plot_data(test_obj, h = test_obj$cv_bw, binned = TRUE),
            aes(x = x, y = y, color = "CV"), linetype = "dashed") +
  geom_line(data = plot_data(test_obj, h = test_obj$amise_bw, binned = TRUE),
            aes(x = x, y = y, color = "AMISE"), linetype = "dashed")
  
```
The kernel density with the AMISE bandwidth resembles the true density more. 

We test our implementation on the faithful dataset. We estimate the waiting time to next eruption (in mins) of the Old Faithful geyser in Yellowstone National Park. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
real_obj <- my_density(faithful$waiting)
real_obj
```

Very different optimal bandwidths. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
ggplot(faithful, aes(x = waiting)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = waiting, y = ..density..)) +
  geom_line(data = plot_data(real_obj, h = real_obj$amise_bw),
            aes(x = x, y = y, color = "Naive"), linetype = "dashed") +
    geom_line(data = plot_data(real_obj, h = real_obj$amise_bw, binned = TRUE, B = 20),
            aes(x = x, y = y, color = "Binned"), linetype = "dashed") +
  scale_color_manual(values = c("Binned" = "blue", 
                                "Naive" = "hotpink"))+
  labs(color = "Density types", title = "Geyser data: AMISE BW", x = "Waiting time", y = "Density")

ggplot(faithful, aes(x = waiting)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = waiting, y = ..density..)) +
  geom_line(data = plot_data(real_obj, h = real_obj$cv_bw),
            aes(x = x, y = y, color = "Naive"), linetype = "dashed") +
  geom_line(data = plot_data(real_obj, h = real_obj$cv_bw, binned = TRUE, B = 20),
            aes(x = x, y = y, color = "Binned"), linetype = "dashed") +
  scale_color_manual(values = c("Binned" = "blue", 
                                "Naive" = "hotpink"))+
  labs(color = "Density types", title = "Geyser data: CV BW", x = "Waiting time", y = "Density")

```
Here the cross validation bandwidth does terrible. We do the same for the eruption time

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
real_obj <- my_density(faithful$eruptions)
real_obj
```

More similar bandwidths. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
ggplot(faithful, aes(x = eruptions)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = eruptions, y = ..density..)) +
  geom_line(data = plot_data(real_obj, h = real_obj$amise_bw),
            aes(x = x, y = y, color = "Naive"), linetype = "dashed") +
    geom_line(data = plot_data(real_obj, h = real_obj$amise_bw, binned = TRUE, B = 20),
            aes(x = x, y = y, color = "Binned"), linetype = "dashed") +
  scale_color_manual(values = c("Binned" = "blue", 
                                "Naive" = "hotpink"))+
  labs(color = "Density types", title = "Geyser data: AMISE BW", x = "Waiting time", y = "Density")

ggplot(faithful, aes(x = eruptions)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = eruptions, y = ..density..)) +
  geom_line(data = plot_data(real_obj, h = real_obj$cv_bw),
            aes(x = x, y = y, color = "Naive"), linetype = "dashed") +
  geom_line(data = plot_data(real_obj, h = real_obj$cv_bw, binned = TRUE, B = 20),
            aes(x = x, y = y, color = "Binned"), linetype = "dashed") +
  scale_color_manual(values = c("Binned" = "blue", 
                                "Naive" = "hotpink"))+
  labs(color = "Density types", title = "Geyser data: CV BW", x = "Waiting time", y = "Density")

```
Again I would say teh AMISE bandwidth does better. Furthermore we can safely conclude that the difference between the binned kernel estimator and the naive kernel estimator is very small, at least for this one particular real data set. 
