<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>The Expectation-Maximization Algorithm</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dina Gyberg Jensen (vbz248)" />
    <meta name="date" content="2024-11-06" />
    <script src="3---Presentation_files/header-attrs-2.28/header-attrs.js"></script>
    <link href="3---Presentation_files/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
    <script src="3---Presentation_files/htmlwidgets-1.6.4/htmlwidgets.js"></script>
    <script src="3---Presentation_files/jquery-1.12.4/jquery.min.js"></script>
    <script src="3---Presentation_files/d3-3.5.6/d3.min.js"></script>
    <link href="3---Presentation_files/profvis-0.3.6.9000/profvis.css" rel="stylesheet" />
    <script src="3---Presentation_files/profvis-0.3.6.9000/profvis.js"></script>
    <script src="3---Presentation_files/profvis-0.3.6.9000/scroll.js"></script>
    <link href="3---Presentation_files/highlight-6.2.0/textmate.css" rel="stylesheet" />
    <script src="3---Presentation_files/highlight-6.2.0/highlight.js"></script>
    <script src="3---Presentation_files/profvis-binding-0.3.8/profvis.js"></script>
    <link rel="stylesheet" href="themer-new.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# The Expectation-Maximization Algorithm
]
.author[
### Dina Gyberg Jensen (vbz248)
]
.institute[
### University of Copenhagen
]
.date[
### 2024-11-06
]

---

&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 18px;
        padding: 1em 4em 1em 4em;
    }
.remark-slide-content &gt; h1 {
  font-size: 40px;
}
.remark-slide-scaler {
    overflow-y: auto;
    overflow-x: auto;
}
&lt;/style&gt;








###Introduction
Let `\(Y=(X,W) \in \mathbb{R}\times [0,\infty)\)` have density:
$$f(x,w)=\frac{1}{\sqrt{\pi\nu\sigma^2}2^{(\nu+1)/2}\Gamma(\nu/2)}w^{\frac{\nu-1}{2}}e^{\frac{w}{2}\left( \frac{(x-\mu)^2}{\nu\sigma^2} \right)} $$
Our goal is to implement an Expectation Maximization algorithm to estimate `\(\mu\)` and `\(\sigma^2\)` given that we observe `\(X\)` but not `\(W\)` and to compute the observed Fisher information.
&lt;br&gt;
Furthermore we wish to compare our implementation to a standard Gradient Descent algorithm.
---
###Marginal Density of X

`\(Y = (X,W)\in\mathbb{R}\times(0,\infty)\)` has joint density:
$$f(x,w)=\frac{1}{\sqrt{\pi \sigma \nu}2^{(\nu+1)/2}\Gamma(\nu/2)}w^{\frac{\nu-1}{2}}e^{-\frac{w}{2}\left(1+\frac{(x-\mu)^2}{\nu\sigma^2} \right)} $$


The marginal density of `\(X\)` is:
`$$f(x)=\int_0^\infty f(x,w)dw=\frac{1}{\sqrt{\pi \sigma \nu}2^{(\nu+1)/2}\Gamma(\nu/2)} \int_0^\infty w^{\frac{\nu-1}{2}}e^{-\frac{w}{2}\left(1+\frac{(x-\mu)^2}{\nu\sigma^2} \right)} dw\\
=\frac{1}{\sqrt{\pi \nu \sigma}}\frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)}\left(1+\frac{(x-\mu)^2}{\nu\sigma^2}\right)^{-\frac{\nu+1}{2}}$$`
Where we have used that the gamma density is given by `\(\Gamma(z)=\int_0^\infty t^{z-1}e^{-t}dt\)` and used the substitution `\(t = \frac{w}{2}\left( 1+\frac{(x-\mu)^2}{\nu\sigma^2} \right)\)`. The result can be easily recognized as a Student's t-distribution with `\(\nu\)` degrees of freedom and location `\(\mu\)` and scale `\(\sigma\)`.

---
###Maximizing Complete Data log-likelihood
Complete data log-likelihood for fixed `\(\nu\)`:
`$$\sum_{i=1}^n\log f(x_i,w_i)=-\sum_{i=1}^n\log\left(\sigma\sqrt{\pi\nu}2^{(\nu+1)/2}\Gamma(\nu/2) \right)+\sum_{i=1}^n\log\left(w_i^{\frac{\nu-1}{2}} \right)-\sum_{i=1}^n\left(\frac{w_i}{2}\left(1+\frac{(x_i-\mu)^2}{\nu\sigma^2} \right) \right)$$`
We differentiate and set equal to 0 to find the MLEs of `\(\mu\)` and `\(\sigma^2\)` given that we observe the full dataset.
.pull-left[ 
`$$\frac{\partial }{\partial\mu}=\frac{1}{\nu\sigma^2}\sum_{i=1}^nw_i(x_i-\mu)$$`
]

.pull-right[ 
`$$\frac{\partial }{\partial\sigma}=-\frac{n}{\sigma}+\sum_{i=1}^n w_i\frac{(x_i-\mu)^2}{\nu\sigma^3}$$`
 ]
.pull-left[ 
`$$\mu_{opt}=\frac{\sum_{i=1}^nw_ix_i}{\sum_{i=1}^nw_i}$$`
]

.pull-right[ 
`$$\sigma^2_{opt} =\frac{1}{n\nu}\sum_{i=1}^nw_i(x_i-\mu)^2$$`
 ]

---
###E-step
For the E-step we need to compute the `\(Q\)`-function
`$$Q(\theta|\theta')=E_{\theta'}\left(\log( f(X,W \ | \ \theta) \ | \ X=x) \right)= \sum_{i=1}^nE_{\theta'}(\log( f(x_i,W_i \ | \ \theta) \ | \ X_i=x_i) )\\
=\sum_{i=1}^nE_{\theta'}\left( \log\left( \frac{1}{\sqrt{\pi \sigma \nu}2^{(\nu+1)/2}\Gamma(\nu/2)}w^{\frac{\nu-1}{2}}e^{-\frac{w}{2}\left(1+\frac{(x-\mu)^2}{\nu\sigma^2} \right)}\right) \right)\\
=-\sum_{i=1}^n\log\left(\sigma\sqrt{\pi\nu}2^{(\nu+1)/2}\Gamma(\nu/2) \right)+\frac{\nu-1}{2}\sum_{i=1}^nE_{\theta'}( \log(W_i\ | \ X_i=x_i))-\frac{1}{2}\left(1+\frac{(x_i-\mu)^2}{\nu\sigma^2} \right)\sum_{i=1}^n E_{\theta'}(W_i \ | \ X_i=x_i)$$`

The conditional distribution of `\(W_i \ | X_i=x_i\)` can be recognized as the gamma distribution with shape `\(k = \frac{\nu+1}{2}\)` and scale `\(t_i = \frac{2}{1+\frac{(x_i-\mu')^2}{\nu\sigma'^2} }\)`. Hence we have:
.pull-left[
$$
E_{\theta'}(W_i \ | \ X_i=x_i)=k\cdot t_i
$$
]
.pull-right[
$$
E_{\theta'}( \log(W_i\ | \ X_i=x_i))=\psi(k)+\log(t_i)
$$
]

---
###M-step
For the M-step we need to maximize the `\(Q\)`-function with respect to `\(\mu\)` and `\(\sigma^2\)`. This can be done analytically:
.pull-left[
`$$\frac{\partial }{\partial\mu}Q(\theta|\theta')=-\sum_{i=1}^n\frac{(x_i-\mu)}{\nu\sigma^2}kt_i\\
\Rightarrow\hat{\mu}_{opt}=\frac{\sum_{i=1}^nx_it_i}{\sum_{i=1}^nt_i}$$`
]

.pull-right[
`$$\frac{\partial }{\partial\sigma}Q(\theta|\theta')=-\frac{n}{\sigma}+\sum_{i=1}^n\frac{(x_i-\mu)^2}{\nu\sigma^3}kt_i \\
\Rightarrow \hat{\sigma}^2_{opt}=\frac{1}{n\nu}k\sum_{i=1}^n(x_i-\mu)^2t_i$$`
]


We note that this means we can actually optimize `\(Q\)` wrt. `\(\mu\)` and `\(\sigma^2\)` without explicitly calculating `\(Q\)`.


---
class: reduce-spacing

###Implementation

``` r
EM_alg &lt;- function(x, param, ny , max_iter = 20, epsilon = 1e-10, cb = NULL){
  #Getting initial parameters
  mu_mark &lt;- param$mu 
  sigma_mark &lt;- param$sigma
  #Defining i and k, which only depends on ny:
  ny &lt;- ny
  k &lt;- (ny + 1) / 2   
  i &lt;- 0
  
  while (i &lt; max_iter) {
    mu_old &lt;- mu_mark
    sigma_old &lt;- sigma_mark
    t_old &lt;- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))
    
    mu_mark &lt;- sum(t_old * x) / sum(t_old)
    sigma_mark &lt;- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)
    #Calling  cb
    if(!is.null(cb)) cb()
    #Checking convergence
    if (sum((c(mu_mark, sigma_mark) - c(mu_old, sigma_old))^2) 
        &lt;= epsilon * (sum(c(mu_mark, sigma_mark)^2) + epsilon)) break
    i &lt;- i + 1
  }
  c(mu_mark, sigma_mark)
}
```

---
###Implementation


S3 object for both simulation and the EM algorithm

- `parameters`-class for `\(\mu\)`, `\(\sigma^2\)` and `\(\nu\)` - and a `sim` function that simulates `\(W\)` from a `\(\mathcal{X}_\nu^2\)`-distribution and then simulates `\(X\)` from a normal distribution with mean `\(\mu\)` and variance `\(\frac{\nu\sigma^2}{w}\)` for `\(W =w\)`.

- `EM`-class for the EM algorithm, with corresponding `summary`, `print` and a `plot`-method. The `plot`-method can both plot the loglikelihood-convergence but also the suboptimality to the true MLE-estimates. We have the true MLE estimates as we simulate data ourselves.

- Stopping criterion is `\(||\theta' - \theta||^2\leq \varepsilon||\theta||^2 + \varepsilon\)`


``` r
EM(sim1$x, parameters(1, 2, 3), 20, 1e-10, par_true = parameters(1, 1, 1))
```

```
## EM algorithm:
## True parameters:
## [1] 1 1 1
## 
## Optimal parameters:
## [1] 0.9863002 1.0591104
## 
## Number of iterations:
## [1] 19
## 
## Total time:
## [1] 0.0003624998
```


---
class: reduce-spacing

###Testing
Testing stability. Simulating 4 different datasets, runnning for different starting points and compare to true MLE.


.pull-left[

Table: Simulated data with c(1,1,1)

|Starting_point   |   mu| sigma|
|:----------------|----:|-----:|
|c(-2, 5)         | 0.99|  1.06|
|c(0.64, 0.247)   | 0.99|  1.06|
|Started in  true | 0.99|  1.06|
|True             | 0.97|  1.04|



Table: Simulated data with c(5,2,1)

|Starting_point   |   mu| sigma|
|:----------------|----:|-----:|
|c(-2, 5)         | 4.96|  1.90|
|c(0.64, 0.247)   | 4.96|  1.90|
|Started in  true | 4.96|  1.90|
|True             | 5.01|  1.87|
]


.pull-right[

Table: Random parameters c(0.59, 0.36, 5.79)

|Starting_point   |   mu| sigma|
|:----------------|----:|-----:|
|c(-2, 5)         | 0.59|  0.38|
|c(0.64, 0.247)   | 0.59|  0.38|
|Started in  true | 0.59|  0.38|
|True             | 0.59|  0.38|



Table: Random parameters c(6.46, 2.47, 1.75)

|Starting_point   |   mu| sigma|
|:----------------|----:|-----:|
|c(-2, 5)         | 6.51|  2.54|
|c(0.64, 0.247)   | 6.51|  2.54|
|Started in  true | 6.51|  2.54|
|True             | 6.48|  2.46|
]


---
###Convergence
Looking at the convergence of the absolute distance to the true parameters:
&lt;br&gt;
&lt;br&gt;
&lt;img src="3---Presentation_files/figure-html/unnamed-chunk-10-1.png" width="1152" style="display: block; margin: auto;" /&gt;



``` r
log_lm &lt;- lm(log(par_norm_diff) ~ i, data = EM1$trace)
exp(coefficients(log_lm)["i"])
```

```
##         i 
## 0.6914975
```


---
###Heatmaps
We now want to visualize the convergence further.

``` r
p1 &lt;- heatmap.My_EM(EM1, theo_par(sim1$x, sim1$w, 1), path = T) + ylim(0,5.5)
p2 &lt;- heatmap.My_EM(EM1, theo_par(sim1$x, sim1$w, 1), gradient = T)
grid.arrange(p1, p2, ncol = 2)
```

&lt;img src="3---Presentation_files/figure-html/unnamed-chunk-12-1.png" width="1152" style="display: block; margin: auto;" /&gt;

---
###Convergence
Looking at the convergence of the negative loglikelihood and of the parameters:
&lt;br&gt;
&lt;br&gt;
&lt;img src="3---Presentation_files/figure-html/unnamed-chunk-13-1.png" width="1152" style="display: block; margin: auto;" /&gt;

---
### Gradiant Descent

As loss function we will use the negative loglikelihood divided by `\(\frac{1}{n}\)`

`$$-\frac{1}{n}\mathcal{l}(\theta) = \frac{1}{n}\sum_{i=1}^n \log(\sigma) + \frac{\nu +1 }{2} \log \left( 1 + \frac{(x_i - \mu)^2}{\nu \sigma^2} \right)$$`
The gradient is

`$$\nabla - \mathcal{l}(\theta) =  \begin{pmatrix} \sum_{i=1}^n  \left(\nu +1 \right) \frac{(x_i - \mu)}{(x_i - \mu)^2 + \nu \sigma^2}  \\ \sum_{i=1}^n \frac{1}{\sigma} -  \frac{(\nu +1)}{  \nu \sigma^2 + (x_i - \mu)^2} \frac{(x_i - \mu)^2}{\sigma} \end{pmatrix}$$`
 
We implement the gradient in the function `grad` and check that the gradient is close to `\(0\)` in the full data MLE estimates.


```
## [1] -0.007513057 -0.005044825
```

---
###Gradient Descent
Now implementing Gradient Descent to compare it to our EM. Wrapped in an S3-function similar to that of the EM. Initial stepsize `\(1\)` and topping criterion is also `\(||\theta' - \theta||^2\leq \varepsilon||\theta||^2 + \varepsilon\)`.

We first look at the convergence of GD for data simulated from `\(parameters = (1,1,1)\)` and with starting points `\((-2,5)\)` - same as for EM.  
&lt;br&gt;


&lt;img src="3---Presentation_files/figure-html/unnamed-chunk-16-1.png" width="1152" /&gt;

---
###Comparison
Looking at the convergence of GD compared to the EM.
&lt;br&gt;
&lt;br&gt;
&lt;img src="3---Presentation_files/figure-html/unnamed-chunk-17-1.png" width="1152" /&gt;
---
#Optimizing GD
As GD is not competitive, we seek to improve it by giving it Polyak momentum. Now the update step is:
`$$x_k = x_{k-1}-\gamma\nabla f(x_{k-1}) + \mu(x_{k-1}-x_{k-2}) \quad \text{for} \quad \mu\in[0,1), x_{-1}=x_0$$`
&lt;img src="3---Presentation_files/figure-html/unnamed-chunk-18-1.png" width="1152" /&gt;

---
###Comparison for larger datasets
Increasing `\(n\)`, to see how that impacts performance of the two.
&lt;img src="3---Presentation_files/figure-html/unnamed-chunk-19-1.png" width="1152" /&gt;


---
###Fischer Information
The empirical Fischer information matrix can be calculated as the empirical variance of the gradient of our `\(Q\)` function. For a single observation we have
`$$\nabla_\theta Q_i(\theta'|\theta')=\nabla_\theta \ell_i(\theta')$$`
Where `\(\ell_i(\theta')\)` is the loglikelihood for a single observation. By using the second Bartlett identity we have that the empirical Fischer information matrix can be calculated as
`$$\mathcal{I}(\hat{\theta}) = \sum_{i=1}^n\left(\nabla_\theta Q_i(\hat{\theta}|\hat{\theta})- N^{-1}\nabla_\theta \ell(\hat{\theta}) \right)\left(\nabla_\theta Q_i(\hat{\theta}|\hat{\theta})- N^{-1}\nabla_\theta \ell(\hat{\theta}) \right)^T$$`
We will calculate this both for `\(\nabla_\theta l(\hat{\theta})=0\)` and without. To see if the fact that `\(\nabla_\theta l(\hat{\theta})\)` is only approximately zero has any effect. We have already calculated the gradient of `\(Q\)` wrt. `\(\mu\)` and `\(\sigma^2\)` for the M-step of our EM.


---
###Fischer information

We will now implement it and compare it to the numerical derivative obtained using `numDeriv`. We will calculate it in the optimal parameters from our EM-algorithm.




``` r
mle_EM &lt;- EM1$est
fisher_information_naive_cent(grad_loglik, c(mle_EM[1], mle_EM[2]), 1, sim1$x)
fisher_information_naive(grad_loglik, c(mle_EM[1], mle_EM[2]), 1, sim1$x)
-numDeriv::jacobian(grad_loglik, x = c(mle_EM[1], mle_EM[2]), nu = 1 , data = sim1$x)
```


.pull-left[

```
## [1] "Naive Fisherinformation"
```

```
##           [,1]      [,2]
## [1,] 456.19471 -15.01916
## [2,] -15.01916 432.11861
```

```
## [1] "Centered Fisherinformation"
```

```
##           [,1]      [,2]
## [1,] 456.19530 -14.99892
## [2,] -14.99892 432.80593
```
]
.pull-right[

```
## [1] "numDeriv"
```

```
##           [,1]      [,2]
## [1,] 446.38465  14.59907
## [2,]  14.59907 441.92867
```
]

---
###Optimizing the EM Algorithm
Even though our EM is fast - we want to see if we can optimize it further. 
<div class="profvis html-widget html-fill-item" id="htmlwidget-06edf45a45b12dc44081" style="width:100%;height:600px;"></div>
<script type="application/json" data-for="htmlwidget-06edf45a45b12dc44081">{"x":{"message":{"prof":{"time":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,3,4,4,4,5,5,6,6,6,7,7,8,8,9,9,10,11,11,12,12,13,13,14,15,15,15,16,16,16,17,17,18,19,19,19,20,20,20,21,21,21,22,22,22,23,23,23,24,24,24,25,25,26,27,27,28,28,28,29,29,30,30,31,31,32,32,33,34,34,35,35,35,36,36,37,38,39,40,40,41,41,42,42,43,44,44,45,45,46,46,47,47,48,49,49,49,50,50,51,51,52,52,53,53,53,54,54,55,55,55],"depth":[36,35,34,33,32,31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,2,1,1,3,2,1,2,1,3,2,1,2,1,2,1,2,1,1,2,1,2,1,2,1,1,3,2,1,3,2,1,2,1,1,3,2,1,3,2,1,3,2,1,3,2,1,3,2,1,3,2,1,2,1,1,2,1,3,2,1,2,1,2,1,2,1,2,1,1,2,1,3,2,1,2,1,1,1,1,2,1,2,1,2,1,1,2,1,2,1,2,1,2,1,1,3,2,1,2,1,2,1,2,1,3,2,1,2,1,3,2,1],"label":["exists","findCenvVar","getInlineInfo","isBaseVar","getFoldFun","constantFoldCall","constantFold","constantFoldCall","constantFold","cmp","cmpPrim2","h","tryInline","cmpCall","cmp","cmpSymbolAssign","h","tryInline","cmpCall","cmp","h","tryInline","cmpCall","cmp","cmpWhileBody","h","tryInline","cmpCall","cmp","h","tryInline","cmpCall","cmp","genCode","cmpfun","compiler:::tryCmpfun","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sum","<GC>","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","<GC>","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","sum","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","mu_mark <- sum(t_old * x) / sum(t_old)","EM_alg","sum","<GC>","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","<GC>","mu_mark <- sum(t_old * x) / sum(t_old)","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sum","<GC>","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","<GC>","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","<GC>","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","<GC>","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","<GC>","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","<GC>","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sum","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","<GC>","mu_mark <- sum(t_old * x) / sum(t_old)","EM_alg","mu_mark <- sum(t_old * x) / sum(t_old)","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","sum","mu_mark <- sum(t_old * x) / sum(t_old)","EM_alg","<GC>","mu_mark <- sum(t_old * x) / sum(t_old)","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sum","sum","sum","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","sum","mu_mark <- sum(t_old * x) / sum(t_old)","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","sum","<GC>","mu_mark <- sum(t_old * x) / sum(t_old)","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)","EM_alg","<GC>","mu_mark <- sum(t_old * x) / sum(t_old)","EM_alg","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg","<GC>","t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))","EM_alg"],"filenum":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,1,1,1,null,1,1,1,1,null,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,null,1,1,null,1,1,1,1,1,null,1,1,null,1,1,null,1,1,null,1,1,null,1,1,null,1,1,1,1,1,1,1,null,1,1,1,1,1,1,1,1,1,1,1,1,1,null,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,null,1,1,1,1,1,1,1,1,null,1,1,1,1,null,1,1],"linenum":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,26,13,26,16,null,16,26,13,26,null,13,26,16,26,13,26,16,26,15,13,26,16,26,15,26,16,null,16,26,null,15,26,13,26,15,null,13,26,null,13,26,null,13,26,null,13,26,null,13,26,null,13,26,13,26,16,16,26,null,15,26,15,26,13,26,13,26,16,26,15,15,26,null,15,26,13,26,16,15,15,13,26,13,26,16,26,15,15,26,13,26,13,26,16,26,15,null,15,26,13,26,16,26,16,26,null,15,26,13,26,null,13,26],"memalloc":[52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,52.28960418701172,60.16123962402344,60.16123962402344,75.42009735107422,90.67906951904297,90.67906951904297,90.67906951904297,74.82010650634766,74.82010650634766,90.07907104492188,90.07907104492188,90.07907104492188,82.44937896728516,82.44937896728516,82.44936370849609,82.44936370849609,67.19052886962891,67.19052886962891,82.44950103759766,74.81992340087891,74.81992340087891,90.07878112792969,90.07878112792969,90.07875061035156,90.07875061035156,74.81993103027344,90.07891845703125,90.07891845703125,90.07891845703125,90.07889556884766,90.07889556884766,90.07889556884766,90.07888031005859,90.07888031005859,82.44931030273438,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,90.07888031005859,67.18618774414062,67.18618774414062,82.44503021240234,105.3334197998047,105.3334197998047,67.18661499023438,67.18661499023438,67.18661499023438,97.70395660400391,97.70395660400391,112.9629364013672,112.9629364013672,97.70392608642578,97.70392608642578,112.962776184082,112.962776184082,97.70379638671875,97.70375823974609,97.70375823974609,112.9627532958984,112.9627532958984,112.9627532958984,90.07452392578125,90.07452392578125,105.333381652832,82.44495391845703,105.3333435058594,90.07437133789062,90.07437133789062,112.9627456665039,112.9627456665039,105.3331832885742,105.3331832885742,74.81555938720703,97.70394897460938,97.70394897460938,112.9629135131836,112.9629135131836,97.70391845703125,97.70391845703125,112.962776184082,112.962776184082,97.70378875732422,112.962776184082,112.962776184082,112.962776184082,112.9627380371094,112.9627380371094,82.44499206542969,82.44499206542969,105.3333740234375,105.3333740234375,74.81597137451172,74.81597137451172,74.81597137451172,97.70394134521484,97.70394134521484,112.9629135131836,112.9629135131836,112.9629135131836],"meminc":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7.871635437011719,0,15.25885772705078,15.25897216796875,0,0,-15.85896301269531,0,15.25896453857422,0,0,-7.629692077636719,0,-1.52587890625e-05,0,-15.25883483886719,0,15.25897216796875,-7.62957763671875,0,15.25885772705078,0,-3.0517578125e-05,0,-15.25881958007812,15.25898742675781,0,0,-2.288818359375e-05,0,0,-1.52587890625e-05,0,-7.629570007324219,7.629570007324219,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-22.89269256591797,0,15.25884246826172,22.88838958740234,0,-38.14680480957031,0,0,30.51734161376953,0,15.25897979736328,0,-15.25901031494141,0,15.25885009765625,0,-15.25897979736328,-3.814697265625e-05,0,15.25899505615234,0,0,-22.88822937011719,0,15.25885772705078,-22.888427734375,22.88838958740234,-15.25897216796875,0,22.88837432861328,0,-7.629562377929688,0,-30.51762390136719,22.88838958740234,0,15.25896453857422,0,-15.25899505615234,0,15.25885772705078,0,-15.25898742675781,15.25898742675781,0,0,-3.814697265625e-05,0,-30.51774597167969,0,22.88838195800781,0,-30.51740264892578,0,0,22.88796997070312,0,15.25897216796875,0,0],"filename":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>",null,"<expr>","<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>",null,"<expr>","<expr>",null,"<expr>","<expr>",null,"<expr>","<expr>",null,"<expr>","<expr>",null,"<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>","<expr>","<expr>",null,"<expr>","<expr>"]},"interval":10,"files":[{"filename":"<expr>","content":"sim1_large <- sim(parameters(1,1,1), 1000000)\nprofvis({\n  EM_alg <- function(x, param, ny , max_iter = 20, epsilon = 1e-10, cb = NULL){\n  mu_mark <- param$mu #Getting initial parameters\n  sigma_mark <- param$sigma\n  ny <- ny\n  k <- (ny + 1) / 2   #Defining i and k, which only depends on ny:\n  i <- 0\n  \n  while (i < max_iter) {\n    mu_old <- mu_mark\n    sigma_old <- sigma_mark\n    t_old <- 2 / (1 + (x - mu_old)^2 / (ny * sigma_old))\n    \n    mu_mark <- sum(t_old * x) / sum(t_old)\n    sigma_mark <- 1 / (length(x) * ny) * k * sum(t_old * (x - mu_mark)^2)\n    #Calling  cb\n    if(!is.null(cb)) cb()\n    #Checking convergence\n    if (sum((c(mu_mark, sigma_mark) - c(mu_old, sigma_old))^2) \n        <= epsilon * (sum(c(mu_mark, sigma_mark)^2) + epsilon)) break\n    i <- i + 1\n  }\n  c(mu_mark, sigma_mark)\n}\n  EM_alg(sim1_large$x, parameters(-2,5,1), ny = 1, 100, 1e-10)\n})","normpath":"<expr>"}],"prof_output":"C:\\Users\\birgi\\AppData\\Local\\Temp\\RtmpGWzfiB\\file3f9c41614ee9.prof","highlight":{"output":["^output\\$"],"gc":["^<GC>$"],"stacktrace":["^\\.\\.stacktraceo(n|ff)\\.\\.$"]},"split":"h"}},"evals":[],"jsHooks":[]}</script>

---
###Optimizing the EM Algorithm
Implementing in `Rcpp` and in `RcppArmadillo` to see if it is possible to optimize.




&lt;img src="3---Presentation_files/figure-html/unnamed-chunk-26-1.png" width="1152" style="display: block; margin: auto;" /&gt;



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"highlightSpans": true,
"ratio": "16:9",
"countIncrementalSlides": true,
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
