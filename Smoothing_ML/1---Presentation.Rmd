---
title: "Density Estimation"
author: 
- "Michaela Lukacova (dns525)"
institute: "University of Copenhagen"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    css: themer-new.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      ratio: 16:9
      countIncrementalSlides: true
      navigation:
        scroll: false
---
<style type="text/css">
.remark-slide-content {
    font-size: 18px;
        padding: 1em 4em 1em 4em;
    }
.remark-slide-content > h1 {
  font-size: 40px;
}
.remark-slide-scaler {
    overflow-y: auto;
    overflow-x: auto;
}
</style>

```{r, include=FALSE, eval = FALSE}
#rmarkdown::render('presentation.rmd')
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(CSwR)
style_mono_accent(
 base_color = "#4f7942")
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(microbenchmark)
library(profvis)
library(knitr)
library(bench)
library(ggplot2)
library(tidyverse)
library(testthat)

theme_set(theme_bw())
knitr::opts_chunk$set(fig.retina = 2)
theme_set(
  theme_bw(base_size = 18) +  # Set base font size and family
    theme(
      text = element_text(size = 15),           # Adjust text size
    )
)
```

```{r source, include=FALSE}
source("~/R/comp_stat/Smoothing_ML/AMISE_bw.R")
source("~/R/comp_stat/Smoothing_ML/cv_bw_l.R")
source("~/R/comp_stat/Smoothing_ML/cv_bw_l_fast.R")
source("~/R/comp_stat/Smoothing_ML/density_object.R")
source("~/R/comp_stat/Smoothing_ML/kern_bin.R")
source("~/R/comp_stat/Smoothing_ML/kern_dens_bin.R")
source("~/R/comp_stat/Smoothing_ML/naive_kern_dens.R")
source("~/R/comp_stat/Smoothing_ML/mse_dens.R")
```

### Kernel Density Estimation

The kernel density estimators approximate an unknown density of data points with the function

$$ \hat{f}(x) = \frac{1}{hN} \sum_{j=1}^N K\left(\frac{x-x_j}{h}\right)$$

For a given kernel $K: \mathbb{R} \rightarrow \mathbb{R}$ and bandwidth parameter $h$.

In our implementations we will use the Epanechnikov kernel. 

$$K(x)=\frac{3}{4}\left(1-x^2\right) 1_{[-1,1]}(x)$$
---
### Naive density estimator

We implement a naive density estimator called `kern_dens1`, the function takes a vector of data points `x`, a bandwidth parameter `h`, a number of gridpoints `m` and a boolean `norm` to normalize the density estimate. The function returns a list with the gridpoints `x` and the density estimate `y`. The `norm`argument is used to normalize the density estimate, so that the gridpoints are equal to r's density function for comparison

```{r}
kern_dens1 <- function(x, h, m = 512, norm = TRUE) {
  
  rg <- range(x)
  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)
  y <- numeric(m)
  
  # we normalize now, so that the gridpoints are equal to r's density function
  if(norm){
    h <- sqrt(5) * h
  }
  
  for (i in seq_along(xx)) {
    
    condition <- abs(xx[i] - x) <= h
    y[i] <- sum((1 - (xx[i] - x)^2 / h^2) * condition)
    
  }
  
  y <- 3 * y / (4 * h * length(x))
  list(x = xx, y = y)
  
}
```

Note that we have already optimized the code a bit in this naive implementation by vectorizing and thinking about performing the operations in the smartest order possible. 

---
### Simulation of data

To test our naive density estimator, we simulate data by drawing 2 times $500$ points from a normal distribution with respectively mean 0 and mean 5. This way we obtain a bimodal distribution. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
# Simulate data
n <- 500
set.seed(123)
x <- c(rnorm(n), rnorm(n, 4))
x_dens <- function(x) 1/2 * dnorm(x) + 1/2 * dnorm(x,4)

p <- ggplot(tibble(x = x), aes(x = x)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = x, y = ..density..)) +
  geom_function(fun = x_dens, alpha = 0.5, color = "blue") 

p
```

---
### S3 class

We have implemented an S3 class `density_object` to store the data and the bandwidth parameter.

```{r}
test_obj <- my_density(x)
```

The object has a `plot` method which we use to check how the naive kernel density estimator approximates the simulated data.

```{r, fig.width=10, fig.height=4, fig.align='center'}
plot(test_obj, h = 0.5)
```
Looks pretty good. 

---
### Check of naive density estimator

We compare the results to the results obtained by using R's density function. This we can do by setting the `p` argument in the `plot` method to $2$. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot(test_obj, h = 0.5, p = 2)
```
They are practically the same!

---
### Check of naive density estimator

We further test that the estimates are correct by using the `test_dens` method. This method tests that the absolute distance between the R `density` function and our own function is less than $10^{-3}$ for 4 different $h$ values equally ditanced in the interval from $0.2$ to $1$. 

```{r}
test_dens(test_obj)
```

---
### Binned density estimator

After profiling and benchmarking the naive density function, we see that it is quite a lot slower than the `density` function in R. We implement a binned density estimator `kern_dens_bin` to speed up the density estimation. The binned density estimator is an alteration of the previous density estimator. It has the advantage of computational efficiency. The binned density estimator is computed as 

$$
\hat{f}(x) = \frac{1}{hN} \sum_{i=1}^B n_j K\left(\frac{x-c_j}{h}\right)
$$
The function bins the observations into $B$ equal length bins spanning the length of the $x$ observations. The number of observations in each bin is $n_j$. $c_j$ is the center of each bin. The computational efficiency is achieved by, instead of computing $K$ in each data point, we only compute $K$ in each centerpoint, and then multiply by the number of observations in that bin. The concern could be that we lose accuracy, but as we'll see, this is not a problem. 

```{r}
kern_dens_bin <- function(x, h, m = 512, B = 100, norm = TRUE) {
  rg <- range(x)
  delta <- (rg[2] - rg[1]) / (B - 1)
  c <- seq(rg[1] + delta/2, rg[2] - delta/2, length.out = B)
  n <- kern_bin(x, rg[1], rg[2], B)
  
  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)
  y <- numeric(m)
  
  # we normalize now, so that the gridpoints are equal to r's density function
  if(norm){
    h <- sqrt(5) * h
  }
  
  for (i in seq_along(xx)) {
    condition <- abs(xx[i] - c)  <=  h
    y[i] <- sum(n * (1 - (xx[i] - c)^2 / h^2) * condition)
  }
  
  y <- 3 * y / (4 * h)
  list(x = xx, y = y)
}
```

---
### Check of binned density estimator

We compare the results to the results obtained by using R's density function. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot(test_obj, h = 0.5, binned = TRUE)
```
They are practically the same!

---
### Bandwidth selection: AMISE plugin

The Epanechnikov kernel is a square-integrable probability density with mean 0. It can be shown that for the Epanechnikov kernel:

$$
\sigma_K^2 = \frac{1}{5} \\
||K||_2^2 = \frac{3}{5}
$$

The AMISE is defined as

$$
AMISE(h) = \frac{||K||_2^2}{nh} + \frac{h^4 \sigma_{K}^4 ||f_0''||_2^2}{4} 
$$
$||f''_0||_2^2$ is the squared $L_2$-norm of the true unknown density. Using various estimate $AMISE(h)$ can be used to estimate the asymptotically optimal bandwidth in a mean integrated squared error sense. By minimizing $AMISE(h)$ the asymptotically optimal oracle bandwidth is 

$$
h_N = \left(\frac{||K||_2^2 }{||f''_0||_2^2 \sigma_K^4} \right)^{1/5}n^{-1/5}
$$

Inserting the values we have for the Epanechnikov kernel

$$
h_N = \left(\frac{15 }{||f''_0||_2^2 } \right)^{1/5}n^{-1/5}
$$

We have now arrived at a circular problem. In order to select bandwidth we need to know $f$, but to estimate $f$ we need the bandwidth. A solution to this problem is to estimate $h$ according to Silverman’s rule of thumb, obtain a pilot density estimate $\tilde{f}$ and compute the squared $L_2$-norm, use this estimate to find $h_N$, in order to arrive at our final kernel density estimate. 

Silverman’s rule of thumb for the Epanechnikov kernel is

$$
\hat{h}_n = (40\sqrt{\pi})^{1/5} \tilde{\sigma}n^{-1/5}
$$

Where $\tilde{\sigma} = \min\{\hat{\sigma}, \frac{\operatorname{IQR}}{1.34}\}$. 

For the Epanechnikov kernel ($H$) with bandwidth $h$ we can compute the squared $L_2$-norm as

$$
||\tilde{f}||^2_2 = \frac{1}{n^2 h^6} \sum_{i=1}^N\sum_{j=1}^N\int H''\left(\frac{x-x_i}{h}\right) H''\left(\frac{x-x_j}{h}\right) dx
$$
We have

$$
H''(x) = -\frac{3}{2} 1_{[-1,1]}(x)
$$
Note

$$
\left(\frac{x-x_i}{h}\right) \in [-1,1] \Leftrightarrow x \in [x_i-r,x_i+r]
$$

So
$$
||\tilde{f}||^2_2 = \frac{9}{4n^2 h^6} \sum_{i=1}^N\sum_{j=1}^N \int_{\max\{x_i - h, x_j -h\}}^{\min\{x_i + h, x_j + h\}} 1 dx = \frac{9}{4n^2 h^6} \sum_{i=1}^N\sum_{j=1}^N  \left(\max\{0,2h - |x_i-x_j|\} \right)
$$
---

---
### AMISE bandwidth selection

The AMISE bandwidth based selection is implemented in the function `AMISE_bw`. 

```{r}

```

```{r}
profvis::profvis({
  AMISE_bw(x)
})
```

---
### A density object

We create a density object and find the optimal bandwidth found by the AMISE_bw function

```{r}
sim_obj <- my_density(x)
sim_obj$amise_bw
```

---
### Cross-validation methods

An alternative to finding the optimal bandwidth by the AMISE plugin method is to use crossvalidation to find the optimal bandwidth from a loglikelihood perspective. The UCV is an alternative measure to choose the optimal bandwidth. We have implemented two functions. One slow:

```{r}
profvis::profvis({
  cv_bw_l(x)
})

profvis::profvis({
  cv_bw_l_fast(x)
})
```

We see that in the fast function, a lot of time is spent computing the condition (the indicator function), and computing the sum. (for loopet tror jeg godt vi kan komme af med...) But the function is much faster than our first attempt. Evt. andre evt. forbedringer: hurtigere paralleilisering, folds osv. 

Our crossvalidation optimal bandwidth:

```{r}
sim_obj$cv_bw
```

Very close to the optimal bandwidth found by the AMISE function. 

---
### Benchmarking bandwidth selection

---
### How well does the density estimator perform?

---
### Binned density estimator

---
### RCPP implementation

---
### Which bandwidth parameter is better?

---
### Which implementation is better?

---
### Test of the implementations using simulated data

Compute the error of the density estimates on simulated data. 

---
### Test of implementation using real data
volcano

To do:
- læse opgave formulering og sikre mig at jeg får besvaret tingene
- bygge en story line op, og vælge de bedste ting at tage med, som viser at jeg har besvaret de ting de går efter
- evt. bygge en pakke 
- implementere i rcpp
