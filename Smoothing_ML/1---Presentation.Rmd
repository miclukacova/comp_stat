---
title: "Density Estimation"
author: 
- "Michaela Lukacova (dns525)"
institute: "University of Copenhagen"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    css: themer-new.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      mathjax: true
      ratio: 16:9
      countIncrementalSlides: true
      navigation:
        scroll: false
    includes:
      in_header: null
    lib_dir: libs

      

---
<style type="text/css">
.remark-slide-content {
    font-size: 18px;
        padding: 1em 4em 1em 4em;
    }
.remark-slide-content > h1 {
  font-size: 40px;
}
.remark-slide-scaler {
    overflow-y: auto;
    overflow-x: auto;
}
</style>

```{r, include=FALSE, eval = FALSE}
#rmarkdown::render('presentation.rmd')
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(CSwR)
style_mono_accent(
 base_color = "#4f7942")
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(microbenchmark)
library(profvis)
library(knitr)
library(bench)
library(ggplot2)
library(tidyverse)
library(testthat)
library(Rcpp)
library(parallel)
library(gridExtra)

theme_set(theme_bw())
knitr::opts_chunk$set(fig.retina = 2)
theme_set(
  theme_bw(base_size = 18) +  # Set base font size and family
    theme(
      text = element_text(size = 15),           # Adjust text size
    )
)
```

```{r source, include=FALSE}
source("~/R/comp_stat/Smoothing_ML/AMISE_bw.R")
source("~/R/comp_stat/Smoothing_ML/cv_bw_l.R")
source("~/R/comp_stat/Smoothing_ML/cv_bw_l_fast.R")
source("~/R/comp_stat/Smoothing_ML/density_object.R")
source("~/R/comp_stat/Smoothing_ML/kern_bin.R")
source("~/R/comp_stat/Smoothing_ML/kern_dens_bin.R")
source("~/R/comp_stat/Smoothing_ML/naive_kern_dens.R")
source("~/R/comp_stat/Smoothing_ML/mse_dens.R")
Rcpp::sourceCpp("rcpp_cw.cpp")
```
### Kernel Density Estimation

Is used to approximate an unknown density with the function

$$ \hat{f}(x) = \frac{1}{hN} \sum_{j=1}^N K\left(\frac{x-x_j}{h}\right)$$

For a given kernel $K: \mathbb{R} \rightarrow \mathbb{R}$ and bandwidth parameter $h$.

We will use the Epanechnikov kernel. 

$$K(x)=\frac{3}{4}\left(1-x^2\right) 1_{[-1,1]}(x)$$

---
### Outline

- Naive kernel density estimator

- Optimized kernel density estimator

- Benchmarking and profiling

- Comparison to R's `density` function

- Bandwidth selection
  + AMISE bandwidth
  + Cross validation bandwidth
  + Optimizing and benchmarking 
  
- Real data density estimation

---
### Naive density estimator

We implement a naive density estimator called `kern_dens1`. 

```{r}
kern_dens1 <- function(x, h, m = 512, norm = TRUE) {
  
  rg <- range(x)
  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)
  y <- numeric(m)
  
  # Normalizing so that the gridpoints equal R's gridpoints
  if(norm){
    h <- sqrt(5) * h
  }
  
  for (i in seq_along(xx)) {
    
    condition <- abs(xx[i] - x) <= h
    y[i] <- sum((1 - (xx[i] - x)^2 / h^2) * condition)
    
  }
  
  y <- 3 * y / (4 * h * length(x))
  list(x = xx, y = y)
  
}
```
---
### Simulation of data

To test our naive density estimator, we simulate data by drawing $500$ points from $\mathcal{N}(-3, 2^2)$ and 500 points from $\mathcal{N}(-3, 2^2)$. This way we obtain a bimodal distribution. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
# Simulate data
n <- 500
set.seed(123)
x <- c(rnorm(n, mean = -3, sd = 2), rnorm(n, mean = 3, sd = 2))
x_dens <- function(x) 1/2 * dnorm(x, -3, 2) + 1/2 * dnorm(x,3,2)

p <- ggplot(tibble(x = x), aes(x = x)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = x, y = ..density..)) +
  geom_function(fun = x_dens, alpha = 0.5, aes(color = "True Dens"))+
  scale_color_manual(values = c("True Dens" = "blue", 
                                "CV" = "hotpink", 
                                "AMISE" = "green3"))+
  labs(color = "Density types", title = "Simulated data", x = "x", y = "Density")

p
```

---
### S3 class

To make the implementation as generel and generic as possible, we have implemented an S3 class `density_object` to store data and bandwidth parameters. It is created by calling the `my_density` function on a vector of data points. 

```{r}
test_obj <- my_density(x)
```

The object has a `plot` method which we use to check how the naive kernel density estimator approximates the simulated data. We call the plot function to check whether our kernel density estimator produces a reasonable approximation of the true density. 

```{r, fig.width=10, fig.height=4, fig.align='center', message = FALSE, warning = FALSE}
plot(test_obj, h = 0.5)
```

---
### Check of naive density estimator

We compare the results to the results obtained by using R's `density` function. This we can do by setting the `p` argument in the `plot` method to $2$. 

```{r, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
plot(test_obj, h = 0.5, p = 2)
```

They are practically the same!

---
### Check of naive density estimator

We further test that the estimates are correct by using the `test_dens` method. This method tests that the absolute distance between the R `density` function and our own function is less than $10^{-3}$ for 4 different $h$ values equally distanced in the interval from $0.2$ to $5$. 

```{r}
test_dens(test_obj)
```

---
### Binned kernel density estimator

- Profiling and benchmarking reveals that the naive density function is quite a lot slower than `density` 
- We implement a binned density estimator `kern_dens_bin` to speed up the density estimation.
- The binned density estimator is computed as 

$$
\hat{f}(x) = \frac{1}{hN} \sum_{i=1}^B n_j K\left(\frac{x-c_j}{h}\right)
$$

- `kern_dens_bin`:
  + Bins the observations into $B$ equal length bins spanning the range of the $x$ observations
  + The number of observations in each bin is $n_j$
  + $c_j$ is the center of each bin. 

The computational efficiency is achieved by, instead of computing $K$ in each data point, we only compute $K$ in each centerpoint, and then multiply by the number of observations in that bin. 

---
### Check of binned density estimator

Again we test the implementation by comparing the results to the results obtained by using R's density function. 

```{r, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
plot(test_obj, h = 0.5, binned = TRUE, B = 100)
```

The estimates are very close to being the same as when using R's density estimator. We use the `test_dens` method to check that the estimates are similar for different $h$ values

```{r}
test_dens(test_obj, binned = TRUE, level = 1e-2)
```

---
### Check of binned density estimator

We plot the differences.

```{r, message=FALSE, warning=FALSE, echo = FALSE, fig.width=10, fig.height=4, fig.align='center'}
plot_diff <- tibble(x = plot_data(test_obj, h = 0.5, binned = TRUE)$x,
                    "Diffs bin" = plot_data(test_obj, h = 0.5, binned = TRUE)$y - 
                      density(test_obj$x, kernel = "epanechnikov", 0.5)$y,
                    "Diffs naive" = plot_data(test_obj, h = 0.5)$y - 
                      density(test_obj$x, kernel = "epanechnikov", 0.5)$y)

ggplot(data = plot_diff, aes(x = x)) + 
  geom_line(aes(y = `Diffs bin`, color = "Binned"), size = 1) +
  geom_line(aes(y = `Diffs naive`, color = "Naive"), size = 1) +
  labs(title = "Differences between R's density function and our own", x = "x", y = "Differences") +
  scale_color_manual(values = c("Binned" = "purple", "Naive" = "hotpink"))

```
---
### Profiling

By profiling the `kern_dens_bin` function we see that the function is quite fast. All the time is spent in the `kern_bin` function, which is a function that computes the number of points in each bin. 

```{r, message=FALSE, warning=FALSE, echo = FALSE}
y <- rnorm(10^8)
profvis::profvis({
  
  kern_dens_bin <- function(x, h, m = 512, B = 100, norm = TRUE, bin = kern_bin) {
  rg <- range(x)
  delta <- (rg[2] - rg[1]) / (B - 1)
  c <- seq(rg[1] + delta/2, rg[2] - delta/2, length.out = B)
  n <- bin(x, rg[1], rg[2], B)
  
  xx <- seq(rg[1] - 3 * h, rg[2] + 3 * h, length.out = m)
  y <- numeric(m)
  
  # we normalize now, so that the gridpoints are equal to r's density function
  if(norm){
    h <- sqrt(5) * h
  }
  
  for (i in seq_along(xx)) {
    condition <- abs(xx[i] - c)  <=  h
    y[i] <- sum(n * (1 - (xx[i] - c)^2 / h^2) * condition)
  }
  
  y <- 3 * y / (4 * h)
  list(x = xx, y = y)
  }
  
  kern_bin <- function(x, l, u, B) {
    w <- numeric(B)
    delta <- (u - l) / (B - 1)
    for (j in seq_along(x)) {
      i <- floor((x[j] - l) / delta + 0.5) + 1
      w[i] <- w[i] + 1
    }
    w / sum(w)
  }


  kern_dens_bin(y, 0.5)
})
```

---
### Optimizing and benchmarking 

We vectorize the `kern_bin` function to speed up the computation. And test that the two functions in fact compute the same.

```{r}
sum(kern_bin(x, range(x)[1], range(x)[2], 100) != kern_bin_fast(x, range(x)[1], range(x)[2], 100)) %>% kable() %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center")
```

And benchmark the different kernel estimators

```{r, message=FALSE, warning=FALSE, echo = FALSE, fig.width=10, fig.height=4, fig.align='center'}
# Generate random numbers
set.seed(19)
y <- rnorm(2^12)

dens_bench <- bench::press(
  k = 2^(7:12),
  {
    bench::mark(
      "Vectorized binned density" = kern_dens_bin(x = y[1:k], h = 0.2, bin = kern_bin_fast),
      "Binned density" = kern_dens_bin(y[1:k], 0.2),
      "Naive" = kern_dens1(y[1:k], 0.2),
      "R's density" = density(y[1:k], kernel = "epanechnikov", 0.2),
      check = FALSE
    )
  }
)

dens_bench %>% 
  mutate(expr = as.character(expression), median = as.numeric(median)) %>% 
  ggplot(aes(k, median, color = expr)) + geom_point() + 
  scale_y_log10() +
  geom_line() + labs(y = "time (ms)")
```

- Large improvements by using the binned density estimator
- Small improvement by vectorizing
- The `tabulate` function

---
### Now to a different question: How to select bandwidth?

We will explore two different approaches to bandwidth selection.
- AMISE plugin
    + Is based on minimizing the asymptotic mean integrated squared error.
    + Can be seen as finding a suitable trade off between the integrated variance of our density estimator and the bias of       the density estimator.
    + Need to assumme $||f''_0||_2^2$ is finite
    + Implemented in the function `AMISE_bw`


- Cross-validation
  + Does not rely on asymptotic results,
  + Chooses the optimal bandwidth by minimizing a certain cross validation criterion
  + We will use a log likelihood criterion
  + Implemented in the function `cv_bw_l` 
  
The quantities can be accessed through the density object. 

```{r}
test_obj
```

---
### Bandwidth selection: AMISE plugin

The Epanechnikov kernel is a square-integrable probability density with mean 0. It can be shown that for the Epanechnikov kernel:

$$
\sigma_K^2 = \frac{1}{5} , \quad
||K||_2^2 = \frac{3}{5}
$$

The AMISE is defined as

$$AMISE(h) = \frac{||K||_2^2}{nh} + \frac{h^4 \sigma_{K}^4 ||f_0''||_2^2}{4}$$

$||f''_0||_2^2$ is the squared $L_2$-norm of the true unknown density. 
---
### Bandwidth selection: AMISE plugin

By minimizing $AMISE(h)$ the asymptotically optimal oracle bandwidth is 

$$
h_N = \left(\frac{||K||_2^2 }{||f''_0||_2^2 \sigma_K^4} \right)^{1/5}n^{-1/5}
$$

Inserting the values we have for the Epanechnikov kernel

$$
h_N = \left(\frac{15 }{||f''_0||_2^2 } \right)^{1/5}n^{-1/5}
$$
- Circular problem
- Solution:
  + Estimate $h$ according to Silverman’s rule of thumb,
  + Obtain a pilot density estimate $\tilde{f}$
  + Compute the squared $L_2$-norm 
  + Use this estimate to find $h_N$

---
### Bandwidth selection: AMISE plugin

Silverman’s rule of thumb for the Epanechnikov kernel is

$$
\hat{h}_n = (40\sqrt{\pi})^{1/5} \tilde{\sigma}n^{-1/5}
$$

Where $\tilde{\sigma} = \min\{\hat{\sigma}, \frac{\operatorname{IQR}}{1.34}\}$. 

For the Epanechnikov kernel $K$ with bandwidth $h$ we can compute the squared $L_2$-norm as

$$||\tilde{f}||^2_2 = \frac{1}{N^2 h^6} \sum_{i=1}^N\sum_{j=1}^N\int K''\left(\frac{x-x_i}{h}\right) K''\left(\frac{x-x_j}{h}\right) dx$$

We have

$$
K''(x) = -\frac{3}{2} 1_{[-1,1]}(x)
$$

Note

$$
\left(\frac{x-x_i}{h}\right) \in [-1,1] \Leftrightarrow x \in [x_i-h,x_i+h]
$$

So

$$||\tilde{f}||^2_2 = \frac{9}{4N^2 h^6} \sum_{i=1}^N\sum_{j=1}^N \int_{\max\{x_i - h, x_j -h\}}^{\min\{x_i + h, x_j + h\}} 1 dx = \frac{9}{4N^2 h^6} \sum_{i=1}^N\sum_{j=1}^N  \left(\max\{0,2h - |x_i-x_j|\} \right)$$

---
### Optimal bandwidth by cross-validation 

- Alternative to AMISE band width
- Log likelihood based cross validation criterion, namely

$$\mathcal{l}_{CV}(h) = \sum_{i=1}^N \log(\hat{f}_h^{-i}(x_i))$$

Here $\hat{f}_h^{-i}$ is the kernel density estimate obtained by leaving out the group containing $x_i$ evaluated in $x_i$, that is

$$\hat{f}_h^{-i}(x_i) = \frac{1}{hN_i} \sum_{j \in I^{-1}} K\left(\frac{x_i -x_j}{h}\right) = \frac{3}{4hN_i} \sum_{j \in I^{-1}} \left( 1-\left(\frac{x_i -x_j}{h}\right)^2\right) 1_{[-h,h]}(x_i - x_j)$$

By maximizing this quantity, we can obtain a bandwidth estimate. We first implemented a naive method that for a sequence of bandwidths $(0.3, 0.4,..., 5)$ computes the log likelihood and picks the smallest bandwidth. We use 10 fold cross validation. This method is quite slow since the log likelihood needs to be computed for every data point for every bandwidth. 

---
### Profiling

If we profile the function we can identify bottlenecks:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
profvis::profvis({
  
  cv_bw_l <- function(x, k = 10, h = seq(0.3, 5, by = 0.1)) {
  
    # Partition
    n <- length(x)
    groups <- sample(rep_len(seq(1,k), length.out = n), replace = FALSE)
    
    # number of obs in each group
    N <- sapply(seq(1,k), function(x) sum(groups == x), simplify = TRUE)
    
    # bandwidth log likelihoods 
    bw_l <- numeric(length(h))
    
    # the kernel density estimates
    f_hat_i <- numeric(n)
    
    for(j in seq_along(h)){
      # Calculating CV density estimates
      for (i in seq_along(x)) {
        k <- groups[i]
        x_m_i <- x[groups != k]
        condition <- (x_m_i - h[j] <= x[i]) & (x[i] <= x_m_i + h[j])
        f_hat_i[i] <- 1 / N[k] * sum((1 - (x[i] - x_m_i)^2 / h[j]^2) * condition)
      }
      f_hat_i <- 3 * f_hat_i / (4 * h[j])
      
      # Calculating log likelihood
      bw_l[j] <- sum(log(f_hat_i))
    }
    
    # Returning the bandwidth that has the largest likelihood 
    return(h[which.max(bw_l)])
  }
  
  cv_bw_l(x)
})
```

The time is spent inside the for loop doing the computations og the $\hat{f}_h^{-i}$'s

---
### Optimizing the cross validation bandwidth selection

- The CV method takes a lot of time. 
- The term $(x_i - x_j)^2$ is being computed over and over for each $h$. 
- We optimize the cross validation band width selection such that this term is computed once, and then used for all $h$. 
- We implement this in the function `cv_bw_l_fast`. We furthermore take the inner for loop and implement it in Rcpp. 

```{r}
cv_bw_l_fast <- function(x, 
                         k = 10,
                         h = seq(0.3, 5, by = 0.1), 
                         loop = inner_loop,
                         do_parallel = FALSE) {
  
  # Partition
  n <- length(x)
  groups <- sample(rep_len(seq(1,k), length.out = n), replace = FALSE)
  
  # number of obs in each group
  N <- sapply(seq(1,k), function(x) sum(groups == x), simplify = TRUE)
  
  # bandwidth log likelihoods and kernel density estimates
  bw_l <- numeric(length(h))
  
  if(do_parallel == TRUE) coress <- detectCores() - 1
  else coress <- 1
  
  # term that does not depend on h
  kern_vals <- outer(x, x, function(x1,y1) (x1 - y1)^2)
  
  bw_l_results <- mclapply(seq_along(h), function(j) {
    kern_vals_h <- 1 - kern_vals / h[j]^2
      
    # Calculating CV density estimates
    f_hat_i <- loop(x, h[j], groups, kern_vals_h, N)
      
    # Calculating log likelihood for bandwidth h[j]
    log_likelihood <- sum(log(f_hat_i))
      
    # Return log likelihood for this bandwidth
    return(log_likelihood)
    }, mc.cores = coress)
    
  bw_l <- unlist(bw_l_results)
  
  # Returning the bandwidth that has the largest likelihood 
  return(h[which.max(bw_l)])
}
```

We test that the Rcpp implementations correspond to the R implementation:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
h <- 0.5
groups <- sample(rep_len(seq(1,5), length.out = length(x)), replace = FALSE)
kern_vals_h <- outer(x, x, function(x1,y1) (x1 - y1)^2)
N <- sapply(seq(1,5), function(x) sum(groups == x), simplify = TRUE)

test_that("Rcpp implementation corresponds to R implementation", {
  expect_equal(
    inner_loop_rcpp(x, h, groups, kern_vals_h, N),
    inner_loop(x, h, groups, kern_vals_h, N),
    tolerance = 10^(-13))})
```

As a last attempt at optimizing, we parallelize the folds using the package `parallel`.

---
### Benchmarking 

To evaluate our optimization we benchmark the naive method, the optimized method and the optimized method with Rcpp, and the optimized method with Rcpp and parallization. 

```{r, message=FALSE, warning=FALSE, echo = FALSE, fig.width=10, fig.height=4, fig.align='center'}
# Generate random numbers
set.seed(19)
y <- rnorm(2^10)

kern_bench <- bench::press(
  k = 2^(7:10),
  {
    bench::mark(
      "Naive" = cv_bw_l(x = y[1:k]),
      "Optimized" = cv_bw_l_fast(x = y[1:k]),
      "Rcpp" = cv_bw_l_fast(x = y[1:k], loop = inner_loop_rcpp),
      "Rcpp and parallel" = cv_bw_l_fast(x = y[1:k], loop = inner_loop_rcpp, do_parallel = TRUE),
      check = FALSE,
      memory = FALSE
    )
  }
)

kern_bench %>% 
  mutate(expr = as.character(expression), median = as.numeric(median)) %>% 
  ggplot(aes(k, median, color = expr)) + geom_point() + 
  scale_y_log10() +
  geom_line() + labs(y = "time (ms)")
```

---
### Randomness of cross validation

Below we run the cross validation procedure 30 times to get an idea of the distribution of the estimates. We try both $k = 5$ and $k= 20$, to see whether one of the two is more stable:

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'} 
xx <- x[1:500]
est5 <- numeric(30)
est20 <- numeric(30)

for(i in 1:30){
  est5[i] <- cv_bw_l_fast(x = xx, loop = inner_loop_rcpp, do_parallel = TRUE, k = 5, h = seq(1, 2.5, by = 0.02))
  est20[i] <- cv_bw_l_fast(x = xx, loop = inner_loop_rcpp, do_parallel = TRUE, k = 20, h = seq(1, 2.5, by = 0.02))
}

grid.arrange(
  ggplot(tibble(x = est5), aes(x = x)) + 
    geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = x, y = ..density..)) +
    labs(title = "k = 5", x = "x", y = "Density"),
  ggplot(tibble(x = est20), aes(x = x)) + 
    geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = x, y = ..density..)) +
    labs(title = "k = 20", x = "x", y = "Density"),
  nrow = 1)
```
A larger $k$ seems to stabilize a bit more. 

---
### Comparing the two bandwidths

Our crossvalidation optimal bandwidth:

```{r, message=FALSE, warning=FALSE, echo = FALSE, fig.width=10, fig.height=4, fig.align='center'}
tibble("CV bw" = test_obj$cv_bw, "AMISE bw" = test_obj$amise_bw) %>% kable() %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center")
```

Plotting the two

```{r, message=FALSE, warning=FALSE, echo = FALSE, fig.width=10, fig.height=4, fig.align='center'}
p +
  geom_line(data = plot_data(test_obj, h = test_obj$cv_bw, binned = TRUE),
            aes(x = x, y = y, color = "CV"), linetype = "dashed", size = 1) +
  geom_line(data = plot_data(test_obj, h = test_obj$amise_bw, binned = TRUE),
            aes(x = x, y = y, color = "AMISE"), linetype = "dashed", size = 1)
  
```

The kernel density with the AMISE bandwidth resembles the true density more. 

---
### Test of implementation using real data

We test our implementation on the faithful dataset. We estimate the waiting time to next eruption (in mins) of the Old Faithful geyser in Yellowstone National Park. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
real_obj <- my_density(faithful$waiting)
tibble("CV bw" = real_obj$cv_bw, "AMISE bw" = real_obj$amise_bw) %>% kable() %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
ggplot(faithful, aes(x = waiting)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = waiting, y = ..density..)) +
  geom_line(data = plot_data(real_obj, h = real_obj$amise_bw),
            aes(x = x, y = y, color = "Naive"), linetype = "dashed", linewidth = 1.1) +
    geom_line(data = plot_data(real_obj, h = real_obj$amise_bw, binned = TRUE, B = 20),
            aes(x = x, y = y, color = "Binned"), linetype = "dashed", linewidth = 1.1) +
  scale_color_manual(values = c("Binned" = "blue", 
                                "Naive" = "hotpink"))+
  labs(color = "Density types", title = "Geyser data: AMISE BW", x = "Waiting time", y = "Density")
```

---

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
ggplot(faithful, aes(x = waiting)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = waiting, y = ..density..)) +
  geom_line(data = plot_data(real_obj, h = real_obj$cv_bw),
            aes(x = x, y = y, color = "Naive"), linetype = "dashed", linewidth = 1.1) +
  geom_line(data = plot_data(real_obj, h = real_obj$cv_bw, binned = TRUE, B = 20),
            aes(x = x, y = y, color = "Binned"), linetype = "dashed", linewidth = 1.1) +
  scale_color_manual(values = c("Binned" = "blue", 
                                "Naive" = "hotpink"))+
  labs(color = "Density types", title = "Geyser data: CV BW", x = "Waiting time", y = "Density")

```

---
We do the same for the Eruption time in mins

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
real_obj <- my_density(faithful$eruptions)
tibble("CV bw" = real_obj$cv_bw, "AMISE bw" = real_obj$amise_bw) %>% kable() %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
ggplot(faithful, aes(x = eruptions)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = eruptions, y = ..density..)) +
  geom_line(data = plot_data(real_obj, h = real_obj$amise_bw),
            aes(x = x, y = y, color = "Naive"), linetype = "dashed", linewidth = 1.1) +
    geom_line(data = plot_data(real_obj, h = real_obj$amise_bw, binned = TRUE, B = 20),
            aes(x = x, y = y, color = "Binned"), linetype = "dashed", linewidth = 1.1) +
  scale_color_manual(values = c("Binned" = "blue", 
                                "Naive" = "hotpink"))+
  labs(color = "Density types", title = "Geyser data: AMISE BW", x = "Eruption time", y = "Density")
```

---

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=4, fig.align='center'}
ggplot(faithful, aes(x = eruptions)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.3, aes(x = eruptions, y = ..density..)) +
  geom_line(data = plot_data(real_obj, h = real_obj$cv_bw),
            aes(x = x, y = y, color = "Naive"), linetype = "dashed", linewidth = 1.1) +
  geom_line(data = plot_data(real_obj, h = real_obj$cv_bw, binned = TRUE, B = 20),
            aes(x = x, y = y, color = "Binned"), linetype = "dashed", linewidth = 1.1) +
  scale_color_manual(values = c("Binned" = "blue", 
                                "Naive" = "hotpink"))+
  labs(color = "Density types", title = "Geyser data: CV BW", x = "Eruption time", y = "Density")

```
 

