---
title: "Log-logistic Dose-response Curves"
author: 
- "Christian Rubjerg Hejstvig-Larsen (brf337)"
- "Dina Gyberg Jensen (vbz248)"
institute: "University of Copenhagen"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      ratio: 16:9
      countIncrementalSlides: true
      navigation:
        scroll: false
---
<style type="text/css">
.remark-slide-content {
    font-size: 18px;
        padding: 1em 4em 1em 4em;
    }
.remark-slide-content > h1 {
  font-size: 40px;
}
.remark-slide-scaler {
    overflow-y: auto;
    overflow-x: auto;
}
</style>
```{r, include=FALSE, eval = FALSE}
rmarkdown::render('presentation.rmd')
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
library(CSwR)
style_mono_accent(
 base_color = "#4f7942")
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(microbenchmark)
library(bench)
library(tidyverse)
library(profvis)
library(bench)
theme_set(theme_bw() + theme(text = element_text(size = 13)))
```
###Introduction
Objective is to use stochastic optimization to estimate the parameters of a log-logistic dose-response model using non-linear least squares estimation. That is obtaining the parameters $\alpha, \beta, \gamma, \rho$ that minimize the loss function:
$$L(X,(\alpha,\beta,\gamma,\rho))=\frac{1}{N}\sum_{i=1}^N\left( y_i - f(x_i| \alpha, \beta,\gamma,\rho)\right)^2$$
<br>
Where the response is given by:
$$Y_i = f(x_i| \alpha, \beta,\gamma,\rho) + \varepsilon_i \hskip5mm \text{with}\hskip2mm \varepsilon_i \stackrel{iid}{\sim} N(0,\omega^2)$$
And the log-logistic dose-response model is given by:
$$f(x_i| \alpha, \beta,\gamma,\rho) = \gamma + \frac{\rho - \gamma}{1 + \exp(\beta \log(x_i) - \alpha)}$$
---
### Test of Algorithm 

xxxx

```{r, warning = FALSE, message = FALSE}

```

---
### Gradient Descent

xxxx

```{r, warning = FALSE, message = FALSE}

```

---
### Decay Schedule

We implement a flexible three-parameter power law family of decay schedules

$$
\gamma_n = \frac{\gamma_0 K}{K + n^{a}}
$$

Where $a \in (0.5,1]$ and $K>0$. $\gamma_0$ is the initial learning rate. If $H$ is strongly convex and the gradient bounded, this decay schedule will ensure convergence. We try different decay schedules, where we vary $a$ and $K$. 

```{r, warning = FALSE, message = FALSE}
source("~/comp_stat/Stochastic_Optimization_ML/GD.R")
source("~/comp_stat/Stochastic_Optimization_ML/SGD.R")
source("~/comp_stat/Stochastic_Optimization_ML/sampler.R")

decay1 <- decay_scheduler(gamma0 = 1, a = 1, K = 1)
decay2 <- decay_scheduler(gamma0 = 1, a = 0.5, K = 10)
decay3 <- decay_scheduler(gamma0 = 1, a = 0.5, n1 = 150, gamma1 = 0.0002)


sgd_decay1 <- SGD(par0 = param$par, grad = grad, gamma = decay1, x = x, y = y,
                           true_par = param$par)

SGD_tracer$clear()
sgd_decay2 <- SGD(par0 = param$par, grad = grad, gamma = decay2, x = x, y = y,
                           true_par = param$par)


SGD_tracer$clear()
sgd_decay3 <- SGD(par0 = param$par, grad = grad, gamma = decay3, x = x, y = y,
                           true_par = param$par)

grid.arrange(plot(sgd_decay1, 1) + ggtitle("a = 1, K = 1"),
             plot(sgd_decay2, 1)+ ggtitle(" a = 0.5, K = 10"), 
             plot(sgd_decay3, 1) + ggtitle("g1 = 0.0001, n1 = 100"),
             nrow = 1)
```
---
### Exploiting Grid Structure 

xxxx

```{r, warning = FALSE, message = FALSE}

```