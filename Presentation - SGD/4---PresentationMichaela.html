<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Log-logistic Dose-response Curves</title>
    <meta charset="utf-8" />
    <meta name="author" content="Christian Rubjerg Hejstvig-Larsen (brf337)" />
    <meta name="author" content="Dina Gyberg Jensen (vbz248)" />
    <meta name="date" content="2024-10-23" />
    <script src="4---PresentationMichaela_files/header-attrs-2.26/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Log-logistic Dose-response Curves
]
.author[
### Christian Rubjerg Hejstvig-Larsen (brf337)
]
.author[
### Dina Gyberg Jensen (vbz248)
]
.institute[
### University of Copenhagen
]
.date[
### 2024-10-23
]

---

&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 18px;
        padding: 1em 4em 1em 4em;
    }
.remark-slide-content &gt; h1 {
  font-size: 40px;
}
.remark-slide-scaler {
    overflow-y: auto;
    overflow-x: auto;
}
&lt;/style&gt;








###Introduction
Objective is to use stochastic optimization to estimate the parameters of a log-logistic dose-response model using non-linear least squares estimation. That is obtaining the parameters `\(\alpha, \beta, \gamma, \rho\)` that minimize the loss function:
`$$L(X,(\alpha,\beta,\gamma,\rho))=\frac{1}{N}\sum_{i=1}^N\left( y_i - f(x_i| \alpha, \beta,\gamma,\rho)\right)^2$$`
&lt;br&gt;
Where the response is given by:
`$$Y_i = f(x_i| \alpha, \beta,\gamma,\rho) + \varepsilon_i \hskip5mm \text{with}\hskip2mm \varepsilon_i \stackrel{iid}{\sim} N(0,\omega^2)$$`
And the log-logistic dose-response model is given by:
`$$f(x_i| \alpha, \beta,\gamma,\rho) = \gamma + \frac{\rho - \gamma}{1 + \exp(\beta \log(x_i) - \alpha)}$$`
---
### Test of Algorithm 

We do a naive test of the algorithm. We simulate a data sets (of size `\(N=1000\)`) for the  parameter values: `\((0.1,1,2.2,1)\)`. 



And run the algorithm with 3 different starting values. 



Very different convergence schemes, converging to different values

![](4---PresentationMichaela_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;

![](4---PresentationMichaela_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

Table: Different starting values

|Par         |  True vals| (1, 1, 1, 1)| (0.2, 2, 4.4, 2)|
|:-----------|----------:|------------:|----------------:|
|alpha (0.1) | -0.1213310|    0.2075029|        0.3929716|
|beta (1.0)  |  1.0014032|    1.1476542|        0.9275918|
|gamma (2.2) |  2.1684862|    2.1755036|        2.3496939|
|rho (1.0)   |  0.8923347|    1.0215186|        0.9961021|


---
### Decay Schedule

We implement a flexible three-parameter power law family of decay schedules

$$
\gamma_n = \frac{\gamma_0 K}{K + n^{a}}
$$

We try two different decay schedules, where we vary `\(a\)` and `\(K\)`. For the first one we let `\(a = 1\)`, `\(K= 0.4\)`. For the second one `\(a = 0.7\)`, `\(K = 1\)`. A variations of this decay schedule is to specify a desired learning rate `\(\gamma_1\)` which should be reached at iteration `\(n_1\)`. These specifications then determine the parameter `\(K\)`. We implement one decay schedule this way. 



![](4---PresentationMichaela_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;![](4---PresentationMichaela_files/figure-html/unnamed-chunk-9-2.png)&lt;!-- --&gt;

---
### Gradient Descent

We have also implemented a gradient descent algorithm. We have created an equivalent class for this algorithm as well. As stopping criterion we use $ | \theta_n - \theta_{n-1}| \leq \epsilon = 10^{-4}$. We use backtracking line search in the algorithm in order to find step length. We check that the algorithm works:

![](4---PresentationMichaela_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;

Table: Different starting values

|Par         | (0.1, 0.8, 2.7, 1.5)| (1, 1, 1, 1)| True vals|
|:-----------|--------------------:|------------:|---------:|
|alpha (0.1) |            0.1624802|    0.5709169| 0.1624802|
|beta (1.0)  |            0.8665684|    1.2024765| 0.8665684|
|gamma (2.2) |            2.3127197|    2.2516662| 2.3127197|
|rho (1.0)   |            0.8988933|    1.1122319| 0.8988933|

---
### Comparison

We compare the performance of the two algorithms. 




Table: GD vs. SGD

|      | True|        GD|        SGD|
|:-----|----:|---------:|----------:|
|alpha |  0.1| 0.5709169| -0.0797157|
|beta  |  1.0| 1.2024765|  1.0872478|
|gamma |  2.2| 2.2516662|  2.1378754|
|rho   |  1.0| 1.1122319|  0.9397566|


![](4---PresentationMichaela_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;![](4---PresentationMichaela_files/figure-html/unnamed-chunk-13-2.png)&lt;!-- --&gt;

---
### Comparison 2

We benchmark the two algorithms. 

![](4---PresentationMichaela_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;![](4---PresentationMichaela_files/figure-html/unnamed-chunk-14-2.png)&lt;!-- --&gt;

---
### Exploiting Grid Structure 

If we sample our `\(x\)`'s from a grid of `\(m\)` points we can exploit the fact that we only have `\(m\)` distinct `\(x\)`-values. We do not need to compute `\(f(x_i| \alpha, \beta,\gamma,\rho)\)` for each `\(i\)`. We can compute the values for each distinct `\(x\)`-value and then use these values to compute the loss function. In the same way we can save computations when computing the derivative of `\(f\)`. We have implemented a `gd_grid` function that exploits this structure. 


```r
gd_grid &lt;- function(
    par,
    t0 = 1e-2,
    maxit = 1000,
    cb = NULL,
    epsilon = 1e-6,
    beta = 0.8,
    alpha = 0.1,
    x,
    y,
    ...) {
  
  x_vals &lt;- unique(x)
  matches &lt;- match(x, x_vals)
  n &lt;- length(x)

  for (i in 1:maxit) {
    
    # Computing 
    fs &lt;- f(par, x_vals)[matches]
    nabla_fs &lt;- sapply(seq_along(x_vals), function(i) nabla_f(par, x_vals[i]))
    
    # Calculations of objective and gradient
    value &lt;- sum((y - fs)^2) 
    gr &lt;- - 2 / n * nabla_fs[,matches] %*% (y - fs)
    
    grad_norm &lt;- sum(gr^2)
    
    # Callback
    if (!is.null(cb)) cb()
    
    t &lt;- t0
    # Proposed descent step
    par_new &lt;- par - t * gr
    new_fs &lt;- f(par_new, x_vals)[matches]
    
    # Convergence criterion based on gradient norm
    if (all(abs(par_new - par) &lt;= epsilon)) break
    
    # Backtracking line search
    while (sum((y - new_fs)^2) &gt; value - alpha * t * grad_norm) {
      t &lt;- beta * t
      par_new &lt;- par - t * gr
      new_fs &lt;- f(par_new, x_vals)[matches]
    }
    par &lt;- par_new
  }
  
  if (i == maxit)  warning("Maximal number, ", maxit, ", of iterations reached")
  
  par
}
```


---
## Benchmarking the two GD versions

We sample data from a grid. 

```
##              x         y
## 1 22026.465795 2.1805075
## 2   148.413159 2.6218884
## 3     7.389056 1.3026705
## 4    54.598150 0.8765165
## 5 22026.465795 1.3062355
## 6 59874.141715 2.5386807
```

We check that the two algorithms return the same output


```
## [1] FALSE
```

Comparing grid version with regular GD. 

![](4---PresentationMichaela_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;![](4---PresentationMichaela_files/figure-html/unnamed-chunk-18-2.png)&lt;!-- --&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"highlightSpans": true,
"ratio": "16:9",
"countIncrementalSlides": true,
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
